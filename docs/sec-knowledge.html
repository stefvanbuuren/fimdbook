<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta name="description" content="Flexible Imputation of Missing Data, Second Edition">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Flexible Imputation of Missing Data, Second Edition" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  <meta name="twitter:description" content="Flexible Imputation of Missing Data, Second Edition" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="sec-modelform.html">
<link rel="next" href="sec-algoptions.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://stefvanbuuren.name/fimd/"> Flexible Imputation of Missing Data</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="want-the-hardcopy.html"><a href="want-the-hardcopy.html"><i class="fa fa-check"></i>Want the hardcopy?</a></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i>Foreword</a></li>
<li class="chapter" data-level="" data-path="preface-to-second-edition.html"><a href="preface-to-second-edition.html"><i class="fa fa-check"></i>Preface to second edition</a></li>
<li class="chapter" data-level="" data-path="preface-to-first-edition.html"><a href="preface-to-first-edition.html"><i class="fa fa-check"></i>Preface to first edition</a></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the author</a></li>
<li class="chapter" data-level="" data-path="symbol-description.html"><a href="symbol-description.html"><i class="fa fa-check"></i>Symbol Description</a></li>
<li class="part"><span><b>I Part I: Basics</b></span></li>
<li class="chapter" data-level="1" data-path="ch-introduction.html"><a href="ch-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="sec-problem.html"><a href="sec-problem.html"><i class="fa fa-check"></i><b>1.1</b> The problem of missing data</a><ul>
<li class="chapter" data-level="1.1.1" data-path="sec-problem.html"><a href="sec-problem.html#sec:current"><i class="fa fa-check"></i><b>1.1.1</b> Current practice</a></li>
<li class="chapter" data-level="1.1.2" data-path="sec-problem.html"><a href="sec-problem.html#sec:changingperspective"><i class="fa fa-check"></i><b>1.1.2</b> Changing perspective on missing data</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="sec-MCAR.html"><a href="sec-MCAR.html"><i class="fa fa-check"></i><b>1.2</b> Concepts of MCAR, MAR and MNAR</a></li>
<li class="chapter" data-level="1.3" data-path="sec-simplesolutions.html"><a href="sec-simplesolutions.html"><i class="fa fa-check"></i><b>1.3</b> Ad-hoc solutions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="sec-simplesolutions.html"><a href="sec-simplesolutions.html#sec:listwise"><i class="fa fa-check"></i><b>1.3.1</b> Listwise deletion</a></li>
<li class="chapter" data-level="1.3.2" data-path="sec-simplesolutions.html"><a href="sec-simplesolutions.html#sec:pairwise"><i class="fa fa-check"></i><b>1.3.2</b> Pairwise deletion</a></li>
<li class="chapter" data-level="1.3.3" data-path="sec-simplesolutions.html"><a href="sec-simplesolutions.html#sec:meanimp"><i class="fa fa-check"></i><b>1.3.3</b> Mean imputation</a></li>
<li class="chapter" data-level="1.3.4" data-path="sec-simplesolutions.html"><a href="sec-simplesolutions.html#sec:regimp"><i class="fa fa-check"></i><b>1.3.4</b> Regression imputation</a></li>
<li class="chapter" data-level="1.3.5" data-path="sec-simplesolutions.html"><a href="sec-simplesolutions.html#sec:sri"><i class="fa fa-check"></i><b>1.3.5</b> Stochastic regression imputation</a></li>
<li class="chapter" data-level="1.3.6" data-path="sec-simplesolutions.html"><a href="sec-simplesolutions.html#sec:locf"><i class="fa fa-check"></i><b>1.3.6</b> LOCF and BOCF</a></li>
<li class="chapter" data-level="1.3.7" data-path="sec-simplesolutions.html"><a href="sec-simplesolutions.html#sec:indicator"><i class="fa fa-check"></i><b>1.3.7</b> Indicator method</a></li>
<li class="chapter" data-level="1.3.8" data-path="sec-simplesolutions.html"><a href="sec-simplesolutions.html#sec:simplesummary"><i class="fa fa-check"></i><b>1.3.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="sec-nutshell.html"><a href="sec-nutshell.html"><i class="fa fa-check"></i><b>1.4</b> Multiple imputation in a nutshell</a><ul>
<li class="chapter" data-level="1.4.1" data-path="sec-nutshell.html"><a href="sec-nutshell.html#procedure"><i class="fa fa-check"></i><b>1.4.1</b> Procedure</a></li>
<li class="chapter" data-level="1.4.2" data-path="sec-nutshell.html"><a href="sec-nutshell.html#reasons-to-use-multiple-imputation"><i class="fa fa-check"></i><b>1.4.2</b> Reasons to use multiple imputation</a></li>
<li class="chapter" data-level="1.4.3" data-path="sec-nutshell.html"><a href="sec-nutshell.html#sec:miexample"><i class="fa fa-check"></i><b>1.4.3</b> Example of multiple imputation</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="sec-goal.html"><a href="sec-goal.html"><i class="fa fa-check"></i><b>1.5</b> Goal of the book</a></li>
<li class="chapter" data-level="1.6" data-path="sec-doesnotcover.html"><a href="sec-doesnotcover.html"><i class="fa fa-check"></i><b>1.6</b> What the book does not cover</a><ul>
<li class="chapter" data-level="1.6.1" data-path="sec-doesnotcover.html"><a href="sec-doesnotcover.html#sec:prevention"><i class="fa fa-check"></i><b>1.6.1</b> Prevention</a></li>
<li class="chapter" data-level="1.6.2" data-path="sec-doesnotcover.html"><a href="sec-doesnotcover.html#sec:weighting"><i class="fa fa-check"></i><b>1.6.2</b> Weighting procedures</a></li>
<li class="chapter" data-level="1.6.3" data-path="sec-doesnotcover.html"><a href="sec-doesnotcover.html#sec:likelihood"><i class="fa fa-check"></i><b>1.6.3</b> Likelihood-based approaches</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="sec-structure.html"><a href="sec-structure.html"><i class="fa fa-check"></i><b>1.7</b> Structure of the book</a></li>
<li class="chapter" data-level="1.8" data-path="ex-ch1.html"><a href="ex-ch1.html"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-mi.html"><a href="ch-mi.html"><i class="fa fa-check"></i><b>2</b> Multiple imputation</a><ul>
<li class="chapter" data-level="2.1" data-path="sec-historic.html"><a href="sec-historic.html"><i class="fa fa-check"></i><b>2.1</b> Historic overview</a><ul>
<li class="chapter" data-level="2.1.1" data-path="sec-historic.html"><a href="sec-historic.html#imputation"><i class="fa fa-check"></i><b>2.1.1</b> Imputation</a></li>
<li class="chapter" data-level="2.1.2" data-path="sec-historic.html"><a href="sec-historic.html#multiple-imputation"><i class="fa fa-check"></i><b>2.1.2</b> Multiple imputation</a></li>
<li class="chapter" data-level="2.1.3" data-path="sec-historic.html"><a href="sec-historic.html#the-expanding-literature-on-multiple-imputation"><i class="fa fa-check"></i><b>2.1.3</b> The expanding literature on multiple imputation</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="sec-idconcepts.html"><a href="sec-idconcepts.html"><i class="fa fa-check"></i><b>2.2</b> Concepts in incomplete data</a><ul>
<li class="chapter" data-level="2.2.1" data-path="sec-idconcepts.html"><a href="sec-idconcepts.html#incomplete-data-perspective"><i class="fa fa-check"></i><b>2.2.1</b> Incomplete-data perspective</a></li>
<li class="chapter" data-level="2.2.2" data-path="sec-idconcepts.html"><a href="sec-idconcepts.html#causes-of-missing-data"><i class="fa fa-check"></i><b>2.2.2</b> Causes of missing data</a></li>
<li class="chapter" data-level="2.2.3" data-path="sec-idconcepts.html"><a href="sec-idconcepts.html#sec:notation"><i class="fa fa-check"></i><b>2.2.3</b> Notation</a></li>
<li class="chapter" data-level="2.2.4" data-path="sec-idconcepts.html"><a href="sec-idconcepts.html#sec:MCARreprise"><i class="fa fa-check"></i><b>2.2.4</b> MCAR, MAR and MNAR again</a></li>
<li class="chapter" data-level="2.2.5" data-path="sec-idconcepts.html"><a href="sec-idconcepts.html#sec:ignorable"><i class="fa fa-check"></i><b>2.2.5</b> Ignorable and nonignorable<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="2.2.6" data-path="sec-idconcepts.html"><a href="sec-idconcepts.html#sec:ignorability"><i class="fa fa-check"></i><b>2.2.6</b> Implications of ignorability</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="sec-whyandwhen.html"><a href="sec-whyandwhen.html"><i class="fa fa-check"></i><b>2.3</b> Why and when multiple imputation works</a><ul>
<li class="chapter" data-level="2.3.1" data-path="sec-whyandwhen.html"><a href="sec-whyandwhen.html#sec:migoal"><i class="fa fa-check"></i><b>2.3.1</b> Goal of multiple imputation</a></li>
<li class="chapter" data-level="2.3.2" data-path="sec-whyandwhen.html"><a href="sec-whyandwhen.html#sec:threesources"><i class="fa fa-check"></i><b>2.3.2</b> Three sources of variation<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="2.3.3" data-path="sec-whyandwhen.html"><a href="sec-whyandwhen.html#sec:proper"><i class="fa fa-check"></i><b>2.3.3</b> Proper imputation</a></li>
<li class="chapter" data-level="2.3.4" data-path="sec-whyandwhen.html"><a href="sec-whyandwhen.html#scope-of-the-imputation-model"><i class="fa fa-check"></i><b>2.3.4</b> Scope of the imputation model</a></li>
<li class="chapter" data-level="2.3.5" data-path="sec-whyandwhen.html"><a href="sec-whyandwhen.html#sec:varianceratios"><i class="fa fa-check"></i><b>2.3.5</b> Variance ratios<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="2.3.6" data-path="sec-whyandwhen.html"><a href="sec-whyandwhen.html#sec:df"><i class="fa fa-check"></i><b>2.3.6</b> Degrees of freedom<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="2.3.7" data-path="sec-whyandwhen.html"><a href="sec-whyandwhen.html#numerical-example"><i class="fa fa-check"></i><b>2.3.7</b> Numerical example</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="sec-inference.html"><a href="sec-inference.html"><i class="fa fa-check"></i><b>2.4</b> Statistical intervals and tests</a><ul>
<li class="chapter" data-level="2.4.1" data-path="sec-inference.html"><a href="sec-inference.html#scalar-or-multi-parameter-inference"><i class="fa fa-check"></i><b>2.4.1</b> Scalar or multi-parameter inference?</a></li>
<li class="chapter" data-level="2.4.2" data-path="sec-inference.html"><a href="sec-inference.html#sec:singlepar"><i class="fa fa-check"></i><b>2.4.2</b> Scalar inference</a></li>
<li class="chapter" data-level="2.4.3" data-path="sec-inference.html"><a href="sec-inference.html#numerical-example-1"><i class="fa fa-check"></i><b>2.4.3</b> Numerical example</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="sec-evaluation.html"><a href="sec-evaluation.html"><i class="fa fa-check"></i><b>2.5</b> How to evaluate imputation methods</a><ul>
<li class="chapter" data-level="2.5.1" data-path="sec-evaluation.html"><a href="sec-evaluation.html#simulation-designs-and-performance-measures"><i class="fa fa-check"></i><b>2.5.1</b> Simulation designs and performance measures</a></li>
<li class="chapter" data-level="2.5.2" data-path="sec-evaluation.html"><a href="sec-evaluation.html#sec:evaluationcriteria"><i class="fa fa-check"></i><b>2.5.2</b> Evaluation criteria</a></li>
<li class="chapter" data-level="2.5.3" data-path="sec-evaluation.html"><a href="sec-evaluation.html#sec:quantifyingbias"><i class="fa fa-check"></i><b>2.5.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="sec-true.html"><a href="sec-true.html"><i class="fa fa-check"></i><b>2.6</b> Imputation is not prediction</a></li>
<li class="chapter" data-level="2.7" data-path="sec-when.html"><a href="sec-when.html"><i class="fa fa-check"></i><b>2.7</b> When not to use multiple imputation</a></li>
<li class="chapter" data-level="2.8" data-path="sec-howmany.html"><a href="sec-howmany.html"><i class="fa fa-check"></i><b>2.8</b> How many imputations?</a></li>
<li class="chapter" data-level="2.9" data-path="sec-exmi.html"><a href="sec-exmi.html"><i class="fa fa-check"></i><b>2.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-univariate.html"><a href="ch-univariate.html"><i class="fa fa-check"></i><b>3</b> Univariate missing data</a><ul>
<li class="chapter" data-level="3.1" data-path="how-to-generate-multiple-imputations.html"><a href="how-to-generate-multiple-imputations.html"><i class="fa fa-check"></i><b>3.1</b> How to generate multiple imputations</a><ul>
<li class="chapter" data-level="3.1.1" data-path="how-to-generate-multiple-imputations.html"><a href="how-to-generate-multiple-imputations.html#predict-method"><i class="fa fa-check"></i><b>3.1.1</b> Predict method</a></li>
<li class="chapter" data-level="3.1.2" data-path="how-to-generate-multiple-imputations.html"><a href="how-to-generate-multiple-imputations.html#sec:meth2"><i class="fa fa-check"></i><b>3.1.2</b> Predict + noise method</a></li>
<li class="chapter" data-level="3.1.3" data-path="how-to-generate-multiple-imputations.html"><a href="how-to-generate-multiple-imputations.html#sec:meth3"><i class="fa fa-check"></i><b>3.1.3</b> Predict + noise + parameter uncertainty</a></li>
<li class="chapter" data-level="3.1.4" data-path="how-to-generate-multiple-imputations.html"><a href="how-to-generate-multiple-imputations.html#a-second-predictor"><i class="fa fa-check"></i><b>3.1.4</b> A second predictor</a></li>
<li class="chapter" data-level="3.1.5" data-path="how-to-generate-multiple-imputations.html"><a href="how-to-generate-multiple-imputations.html#drawing-from-the-observed-data"><i class="fa fa-check"></i><b>3.1.5</b> Drawing from the observed data</a></li>
<li class="chapter" data-level="3.1.6" data-path="how-to-generate-multiple-imputations.html"><a href="how-to-generate-multiple-imputations.html#conclusion"><i class="fa fa-check"></i><b>3.1.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec-linearnormal.html"><a href="sec-linearnormal.html"><i class="fa fa-check"></i><b>3.2</b> Imputation under the normal linear normal</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sec-linearnormal.html"><a href="sec-linearnormal.html#sec:linearoverview"><i class="fa fa-check"></i><b>3.2.1</b> Overview</a></li>
<li class="chapter" data-level="3.2.2" data-path="sec-linearnormal.html"><a href="sec-linearnormal.html#sec:linearalgorithm"><i class="fa fa-check"></i><b>3.2.2</b> Algorithms<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="3.2.3" data-path="sec-linearnormal.html"><a href="sec-linearnormal.html#sec:perflin"><i class="fa fa-check"></i><b>3.2.3</b> Performance</a></li>
<li class="chapter" data-level="3.2.4" data-path="sec-linearnormal.html"><a href="sec-linearnormal.html#sec:generateuni"><i class="fa fa-check"></i><b>3.2.4</b> Generating MAR missing data</a></li>
<li class="chapter" data-level="3.2.5" data-path="sec-linearnormal.html"><a href="sec-linearnormal.html#sec:generatemulti"><i class="fa fa-check"></i><b>3.2.5</b> MAR missing data generation in multivariate data</a></li>
<li class="chapter" data-level="3.2.6" data-path="sec-linearnormal.html"><a href="sec-linearnormal.html#conclusion-1"><i class="fa fa-check"></i><b>3.2.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sec-nonnormal.html"><a href="sec-nonnormal.html"><i class="fa fa-check"></i><b>3.3</b> Imputation under non-normal distributions</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sec-nonnormal.html"><a href="sec-nonnormal.html#overview"><i class="fa fa-check"></i><b>3.3.1</b> Overview</a></li>
<li class="chapter" data-level="3.3.2" data-path="sec-nonnormal.html"><a href="sec-nonnormal.html#sec:tdist"><i class="fa fa-check"></i><b>3.3.2</b> Imputation from the <span class="math inline">\(t\)</span>-distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sec-pmm.html"><a href="sec-pmm.html"><i class="fa fa-check"></i><b>3.4</b> Predictive mean matching</a><ul>
<li class="chapter" data-level="3.4.1" data-path="sec-pmm.html"><a href="sec-pmm.html#overview-1"><i class="fa fa-check"></i><b>3.4.1</b> Overview</a></li>
<li class="chapter" data-level="3.4.2" data-path="sec-pmm.html"><a href="sec-pmm.html#sec:pmmcomputation"><i class="fa fa-check"></i><b>3.4.2</b> Computational details<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="3.4.3" data-path="sec-pmm.html"><a href="sec-pmm.html#number-of-donors"><i class="fa fa-check"></i><b>3.4.3</b> Number of donors</a></li>
<li class="chapter" data-level="3.4.4" data-path="sec-pmm.html"><a href="sec-pmm.html#pitfalls"><i class="fa fa-check"></i><b>3.4.4</b> Pitfalls</a></li>
<li class="chapter" data-level="3.4.5" data-path="sec-pmm.html"><a href="sec-pmm.html#conclusion-2"><i class="fa fa-check"></i><b>3.4.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="sec-cart.html"><a href="sec-cart.html"><i class="fa fa-check"></i><b>3.5</b> Classification and regression trees</a><ul>
<li class="chapter" data-level="3.5.1" data-path="sec-cart.html"><a href="sec-cart.html#sec:cartoverview"><i class="fa fa-check"></i><b>3.5.1</b> Overview</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="sec-categorical.html"><a href="sec-categorical.html"><i class="fa fa-check"></i><b>3.6</b> Categorical data</a><ul>
<li class="chapter" data-level="3.6.1" data-path="sec-categorical.html"><a href="sec-categorical.html#sec:categoricaloverview"><i class="fa fa-check"></i><b>3.6.1</b> Generalized linear model</a></li>
<li class="chapter" data-level="3.6.2" data-path="sec-categorical.html"><a href="sec-categorical.html#perfect-predictionspadesuit"><i class="fa fa-check"></i><b>3.6.2</b> Perfect prediction<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="3.6.3" data-path="sec-categorical.html"><a href="sec-categorical.html#evaluation"><i class="fa fa-check"></i><b>3.6.3</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="other-data-types.html"><a href="other-data-types.html"><i class="fa fa-check"></i><b>3.7</b> Other data types</a><ul>
<li class="chapter" data-level="3.7.1" data-path="other-data-types.html"><a href="other-data-types.html#sec:count"><i class="fa fa-check"></i><b>3.7.1</b> Count data</a></li>
<li class="chapter" data-level="3.7.2" data-path="other-data-types.html"><a href="other-data-types.html#sec:semi"><i class="fa fa-check"></i><b>3.7.2</b> Semi-continuous data</a></li>
<li class="chapter" data-level="3.7.3" data-path="other-data-types.html"><a href="other-data-types.html#sec:censored"><i class="fa fa-check"></i><b>3.7.3</b> Censored, truncated and rounded data</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="sec-nonignorable.html"><a href="sec-nonignorable.html"><i class="fa fa-check"></i><b>3.8</b> Nonignorable missing data</a><ul>
<li class="chapter" data-level="3.8.1" data-path="sec-nonignorable.html"><a href="sec-nonignorable.html#sec:nonignorableoverview"><i class="fa fa-check"></i><b>3.8.1</b> Overview</a></li>
<li class="chapter" data-level="3.8.2" data-path="sec-nonignorable.html"><a href="sec-nonignorable.html#sec:selectionmodel"><i class="fa fa-check"></i><b>3.8.2</b> Selection model</a></li>
<li class="chapter" data-level="3.8.3" data-path="sec-nonignorable.html"><a href="sec-nonignorable.html#sec:patternmixturemodel"><i class="fa fa-check"></i><b>3.8.3</b> Pattern-mixture model</a></li>
<li class="chapter" data-level="3.8.4" data-path="sec-nonignorable.html"><a href="sec-nonignorable.html#sec:convert"><i class="fa fa-check"></i><b>3.8.4</b> Converting selection and pattern-mixture models</a></li>
<li class="chapter" data-level="3.8.5" data-path="sec-nonignorable.html"><a href="sec-nonignorable.html#sec:ch3sensitivity"><i class="fa fa-check"></i><b>3.8.5</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="3.8.6" data-path="sec-nonignorable.html"><a href="sec-nonignorable.html#role-of-sensitivity-analysis"><i class="fa fa-check"></i><b>3.8.6</b> Role of sensitivity analysis</a></li>
<li class="chapter" data-level="3.8.7" data-path="sec-nonignorable.html"><a href="sec-nonignorable.html#recent-developments"><i class="fa fa-check"></i><b>3.8.7</b> Recent developments</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="ex-ch-univariate.html"><a href="ex-ch-univariate.html"><i class="fa fa-check"></i><b>3.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-multivariate.html"><a href="ch-multivariate.html"><i class="fa fa-check"></i><b>4</b> Multivariate missing data</a><ul>
<li class="chapter" data-level="4.1" data-path="missing-data-pattern.html"><a href="missing-data-pattern.html"><i class="fa fa-check"></i><b>4.1</b> Missing data pattern</a><ul>
<li class="chapter" data-level="4.1.1" data-path="missing-data-pattern.html"><a href="missing-data-pattern.html#sec:patternoverview"><i class="fa fa-check"></i><b>4.1.1</b> Overview</a></li>
<li class="chapter" data-level="4.1.2" data-path="missing-data-pattern.html"><a href="missing-data-pattern.html#sec:mdpattern"><i class="fa fa-check"></i><b>4.1.2</b> Summary statistics</a></li>
<li class="chapter" data-level="4.1.3" data-path="missing-data-pattern.html"><a href="missing-data-pattern.html#sec:flux"><i class="fa fa-check"></i><b>4.1.3</b> Influx and outflux</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec-issues.html"><a href="sec-issues.html"><i class="fa fa-check"></i><b>4.2</b> Issues in multivariate imputation</a></li>
<li class="chapter" data-level="4.3" data-path="sec-monotone.html"><a href="sec-monotone.html"><i class="fa fa-check"></i><b>4.3</b> Monotone data imputation</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sec-monotone.html"><a href="sec-monotone.html#sec:monoverview"><i class="fa fa-check"></i><b>4.3.1</b> Overview</a></li>
<li class="chapter" data-level="4.3.2" data-path="sec-monotone.html"><a href="sec-monotone.html#sec:monalgorithm"><i class="fa fa-check"></i><b>4.3.2</b> Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sec-JM.html"><a href="sec-JM.html"><i class="fa fa-check"></i><b>4.4</b> Joint modeling</a><ul>
<li class="chapter" data-level="4.4.1" data-path="sec-JM.html"><a href="sec-JM.html#overview-2"><i class="fa fa-check"></i><b>4.4.1</b> Overview</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec-JM.html"><a href="sec-JM.html#continuous-data"><i class="fa fa-check"></i><b>4.4.2</b> Continuous data</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec-JM.html"><a href="sec-JM.html#sec:jmcategorical"><i class="fa fa-check"></i><b>4.4.3</b> Categorical data</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sec-FCS.html"><a href="sec-FCS.html"><i class="fa fa-check"></i><b>4.5</b> Fully conditional specification</a><ul>
<li class="chapter" data-level="4.5.1" data-path="sec-FCS.html"><a href="sec-FCS.html#overview-3"><i class="fa fa-check"></i><b>4.5.1</b> Overview</a></li>
<li class="chapter" data-level="4.5.2" data-path="sec-FCS.html"><a href="sec-FCS.html#sec:MICE"><i class="fa fa-check"></i><b>4.5.2</b> The MICE algorithm</a></li>
<li class="chapter" data-level="4.5.3" data-path="sec-FCS.html"><a href="sec-FCS.html#sec:compatibility"><i class="fa fa-check"></i><b>4.5.3</b> Compatibility<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="4.5.4" data-path="sec-FCS.html"><a href="sec-FCS.html#sec:congeniality"><i class="fa fa-check"></i><b>4.5.4</b> Congeniality or compatibility?</a></li>
<li class="chapter" data-level="4.5.5" data-path="sec-FCS.html"><a href="sec-FCS.html#sec:modelbased"><i class="fa fa-check"></i><b>4.5.5</b> Model-based and data-based imputation</a></li>
<li class="chapter" data-level="4.5.6" data-path="sec-FCS.html"><a href="sec-FCS.html#sec:howlarget"><i class="fa fa-check"></i><b>4.5.6</b> Number of iterations</a></li>
<li class="chapter" data-level="4.5.7" data-path="sec-FCS.html"><a href="sec-FCS.html#sec:slowconvergence"><i class="fa fa-check"></i><b>4.5.7</b> Example of slow convergence</a></li>
<li class="chapter" data-level="4.5.8" data-path="sec-FCS.html"><a href="sec-FCS.html#performance"><i class="fa fa-check"></i><b>4.5.8</b> Performance</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="fcs-and-jm.html"><a href="fcs-and-jm.html"><i class="fa fa-check"></i><b>4.6</b> FCS and JM</a><ul>
<li class="chapter" data-level="4.6.1" data-path="fcs-and-jm.html"><a href="fcs-and-jm.html#relations-between-fcs-and-jm"><i class="fa fa-check"></i><b>4.6.1</b> Relations between FCS and JM</a></li>
<li class="chapter" data-level="4.6.2" data-path="fcs-and-jm.html"><a href="fcs-and-jm.html#comparisons"><i class="fa fa-check"></i><b>4.6.2</b> Comparisons</a></li>
<li class="chapter" data-level="4.6.3" data-path="fcs-and-jm.html"><a href="fcs-and-jm.html#illustration"><i class="fa fa-check"></i><b>4.6.3</b> Illustration</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="mice-extensions.html"><a href="mice-extensions.html"><i class="fa fa-check"></i><b>4.7</b> MICE extensions</a><ul>
<li class="chapter" data-level="4.7.1" data-path="mice-extensions.html"><a href="mice-extensions.html#skipping-imputations-and-overimputation"><i class="fa fa-check"></i><b>4.7.1</b> Skipping imputations and overimputation</a></li>
<li class="chapter" data-level="4.7.2" data-path="mice-extensions.html"><a href="mice-extensions.html#sec:blockvar"><i class="fa fa-check"></i><b>4.7.2</b> Blocks of variables, hybrid imputation</a></li>
<li class="chapter" data-level="4.7.3" data-path="mice-extensions.html"><a href="mice-extensions.html#sec:blockunit"><i class="fa fa-check"></i><b>4.7.3</b> Blocks of units, monotone blocks</a></li>
<li class="chapter" data-level="4.7.4" data-path="mice-extensions.html"><a href="mice-extensions.html#sec:tile"><i class="fa fa-check"></i><b>4.7.4</b> Tile imputation</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="conclusion-3.html"><a href="conclusion-3.html"><i class="fa fa-check"></i><b>4.8</b> Conclusion</a></li>
<li class="chapter" data-level="4.9" data-path="ex-ch-multivariate.html"><a href="ex-ch-multivariate.html"><i class="fa fa-check"></i><b>4.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-analysis.html"><a href="ch-analysis.html"><i class="fa fa-check"></i><b>5</b> Analysis of imputed data</a><ul>
<li class="chapter" data-level="5.1" data-path="workflow.html"><a href="workflow.html"><i class="fa fa-check"></i><b>5.1</b> Workflow</a><ul>
<li class="chapter" data-level="5.1.1" data-path="workflow.html"><a href="workflow.html#sec:goodworkflows"><i class="fa fa-check"></i><b>5.1.1</b> Recommended workflows</a></li>
<li class="chapter" data-level="5.1.2" data-path="workflow.html"><a href="workflow.html#sec:badworkflowa"><i class="fa fa-check"></i><b>5.1.2</b> Not recommended workflow: Averaging the data</a></li>
<li class="chapter" data-level="5.1.3" data-path="workflow.html"><a href="workflow.html#sec:badworkflowb"><i class="fa fa-check"></i><b>5.1.3</b> Not recommended workflow: Stack imputed data</a></li>
<li class="chapter" data-level="5.1.4" data-path="workflow.html"><a href="workflow.html#sec:repeated"><i class="fa fa-check"></i><b>5.1.4</b> Repeated analyses</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="sec-pooling.html"><a href="sec-pooling.html"><i class="fa fa-check"></i><b>5.2</b> Parameter pooling</a><ul>
<li class="chapter" data-level="5.2.1" data-path="sec-pooling.html"><a href="sec-pooling.html#scalar-inference-of-normal-quantities"><i class="fa fa-check"></i><b>5.2.1</b> Scalar inference of normal quantities</a></li>
<li class="chapter" data-level="5.2.2" data-path="sec-pooling.html"><a href="sec-pooling.html#sec:poolnon"><i class="fa fa-check"></i><b>5.2.2</b> Scalar inference of non-normal quantities</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="sec-multiparameter.html"><a href="sec-multiparameter.html"><i class="fa fa-check"></i><b>5.3</b> Multi-parameter inference</a><ul>
<li class="chapter" data-level="5.3.1" data-path="sec-multiparameter.html"><a href="sec-multiparameter.html#sec:wald"><i class="fa fa-check"></i><b>5.3.1</b> <span class="math inline">\(D_1\)</span> Multivariate Wald test</a></li>
<li class="chapter" data-level="5.3.2" data-path="sec-multiparameter.html"><a href="sec-multiparameter.html#sec:chi"><i class="fa fa-check"></i><b>5.3.2</b> <span class="math inline">\(D_2\)</span> Combining test statistics<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="5.3.3" data-path="sec-multiparameter.html"><a href="sec-multiparameter.html#sec:likelihoodratio"><i class="fa fa-check"></i><b>5.3.3</b> <span class="math inline">\(D_3\)</span> Likelihood ratio test<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="5.3.4" data-path="sec-multiparameter.html"><a href="sec-multiparameter.html#d_1-d_2-or-d_3"><i class="fa fa-check"></i><b>5.3.4</b> <span class="math inline">\(D_1\)</span>, <span class="math inline">\(D_2\)</span> or <span class="math inline">\(D_3\)</span>?</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="sec-stepwise.html"><a href="sec-stepwise.html"><i class="fa fa-check"></i><b>5.4</b> Stepwise model selection</a><ul>
<li class="chapter" data-level="5.4.1" data-path="sec-stepwise.html"><a href="sec-stepwise.html#variable-selection-techniques"><i class="fa fa-check"></i><b>5.4.1</b> Variable selection techniques</a></li>
<li class="chapter" data-level="5.4.2" data-path="sec-stepwise.html"><a href="sec-stepwise.html#computation"><i class="fa fa-check"></i><b>5.4.2</b> Computation</a></li>
<li class="chapter" data-level="5.4.3" data-path="sec-stepwise.html"><a href="sec-stepwise.html#sec:optimism"><i class="fa fa-check"></i><b>5.4.3</b> Model optimism</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="parallel-computation.html"><a href="parallel-computation.html"><i class="fa fa-check"></i><b>5.5</b> Parallel computation</a></li>
<li class="chapter" data-level="5.6" data-path="conclusion-4.html"><a href="conclusion-4.html"><i class="fa fa-check"></i><b>5.6</b> Conclusion</a></li>
<li class="chapter" data-level="5.7" data-path="ex-ch-analysis.html"><a href="ex-ch-analysis.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Part II: Advanced techniques</b></span></li>
<li class="chapter" data-level="6" data-path="ch-practice.html"><a href="ch-practice.html"><i class="fa fa-check"></i><b>6</b> Imputation in practice</a><ul>
<li class="chapter" data-level="6.1" data-path="sec-choices.html"><a href="sec-choices.html"><i class="fa fa-check"></i><b>6.1</b> Overview of modeling choices</a></li>
<li class="chapter" data-level="6.2" data-path="sec-whenignorable.html"><a href="sec-whenignorable.html"><i class="fa fa-check"></i><b>6.2</b> Ignorable or nonignorable?</a></li>
<li class="chapter" data-level="6.3" data-path="sec-modelform.html"><a href="sec-modelform.html"><i class="fa fa-check"></i><b>6.3</b> Model form and predictors</a><ul>
<li class="chapter" data-level="6.3.1" data-path="sec-modelform.html"><a href="sec-modelform.html#model-form"><i class="fa fa-check"></i><b>6.3.1</b> Model form</a></li>
<li class="chapter" data-level="6.3.2" data-path="sec-modelform.html"><a href="sec-modelform.html#sec:predictors"><i class="fa fa-check"></i><b>6.3.2</b> Predictors</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="sec-knowledge.html"><a href="sec-knowledge.html"><i class="fa fa-check"></i><b>6.4</b> Derived variables</a><ul>
<li class="chapter" data-level="6.4.1" data-path="sec-knowledge.html"><a href="sec-knowledge.html#sec:ratio"><i class="fa fa-check"></i><b>6.4.1</b> Ratio of two variables</a></li>
<li class="chapter" data-level="6.4.2" data-path="sec-knowledge.html"><a href="sec-knowledge.html#sec:interactions"><i class="fa fa-check"></i><b>6.4.2</b> Interaction terms</a></li>
<li class="chapter" data-level="6.4.3" data-path="sec-knowledge.html"><a href="sec-knowledge.html#sec:quadratic"><i class="fa fa-check"></i><b>6.4.3</b> Quadratic relations<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="6.4.4" data-path="sec-knowledge.html"><a href="sec-knowledge.html#compositional-dataspadesuit"><i class="fa fa-check"></i><b>6.4.4</b> Compositional data<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="6.4.5" data-path="sec-knowledge.html"><a href="sec-knowledge.html#sec:sumscores"><i class="fa fa-check"></i><b>6.4.5</b> Sum scores</a></li>
<li class="chapter" data-level="6.4.6" data-path="sec-knowledge.html"><a href="sec-knowledge.html#conditional-imputation"><i class="fa fa-check"></i><b>6.4.6</b> Conditional imputation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="sec-algoptions.html"><a href="sec-algoptions.html"><i class="fa fa-check"></i><b>6.5</b> Algorithmic options</a><ul>
<li class="chapter" data-level="6.5.1" data-path="sec-algoptions.html"><a href="sec-algoptions.html#sec:visit"><i class="fa fa-check"></i><b>6.5.1</b> Visit sequence</a></li>
<li class="chapter" data-level="6.5.2" data-path="sec-algoptions.html"><a href="sec-algoptions.html#sec:convergence"><i class="fa fa-check"></i><b>6.5.2</b> Convergence</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="sec-diagnostics.html"><a href="sec-diagnostics.html"><i class="fa fa-check"></i><b>6.6</b> Diagnostics</a><ul>
<li class="chapter" data-level="6.6.1" data-path="sec-diagnostics.html"><a href="sec-diagnostics.html#sec:fitversus"><i class="fa fa-check"></i><b>6.6.1</b> Model fit versus distributional discrepancy</a></li>
<li class="chapter" data-level="6.6.2" data-path="sec-diagnostics.html"><a href="sec-diagnostics.html#diagnostic-graphs"><i class="fa fa-check"></i><b>6.6.2</b> Diagnostic graphs</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="conclusion-5.html"><a href="conclusion-5.html"><i class="fa fa-check"></i><b>6.7</b> Conclusion</a></li>
<li class="chapter" data-level="6.8" data-path="ex-ch-practice.html"><a href="ex-ch-practice.html"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-multilevel.html"><a href="ch-multilevel.html"><i class="fa fa-check"></i><b>7</b> Multilevel multiple imputation</a><ul>
<li class="chapter" data-level="7.1" data-path="sec-multi-intro.html"><a href="sec-multi-intro.html"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="sec-threeformulations.html"><a href="sec-threeformulations.html"><i class="fa fa-check"></i><b>7.2</b> Notation for multilevel models</a></li>
<li class="chapter" data-level="7.3" data-path="sec-missmult.html"><a href="sec-missmult.html"><i class="fa fa-check"></i><b>7.3</b> Missing values in multilevel data</a><ul>
<li class="chapter" data-level="7.3.1" data-path="sec-missmult.html"><a href="sec-missmult.html#practical-issues-in-multilevel-imputation"><i class="fa fa-check"></i><b>7.3.1</b> Practical issues in multilevel imputation</a></li>
<li class="chapter" data-level="7.3.2" data-path="sec-missmult.html"><a href="sec-missmult.html#ad-hoc-solutions-for-multilevel-data"><i class="fa fa-check"></i><b>7.3.2</b> Ad-hoc solutions for multilevel data</a></li>
<li class="chapter" data-level="7.3.3" data-path="sec-missmult.html"><a href="sec-missmult.html#likelihood-solutions"><i class="fa fa-check"></i><b>7.3.3</b> Likelihood solutions</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="sec-mljoint.html"><a href="sec-mljoint.html"><i class="fa fa-check"></i><b>7.4</b> Multilevel imputation by joint modeling</a></li>
<li class="chapter" data-level="7.5" data-path="sec-mlfcs.html"><a href="sec-mlfcs.html"><i class="fa fa-check"></i><b>7.5</b> Multilevel imputation by fully conditional specification</a><ul>
<li class="chapter" data-level="7.5.1" data-path="sec-mlfcs.html"><a href="sec-mlfcs.html#sec:clustermeans"><i class="fa fa-check"></i><b>7.5.1</b> Add cluster means of predictors</a></li>
<li class="chapter" data-level="7.5.2" data-path="sec-mlfcs.html"><a href="sec-mlfcs.html#sec:hetero"><i class="fa fa-check"></i><b>7.5.2</b> Model cluster heterogeneity</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="sec-multioutcome.html"><a href="sec-multioutcome.html"><i class="fa fa-check"></i><b>7.6</b> Continuous outcome</a><ul>
<li class="chapter" data-level="7.6.1" data-path="sec-multioutcome.html"><a href="sec-multioutcome.html#general-principle"><i class="fa fa-check"></i><b>7.6.1</b> General principle</a></li>
<li class="chapter" data-level="7.6.2" data-path="sec-multioutcome.html"><a href="sec-multioutcome.html#methods"><i class="fa fa-check"></i><b>7.6.2</b> Methods</a></li>
<li class="chapter" data-level="7.6.3" data-path="sec-multioutcome.html"><a href="sec-multioutcome.html#sec:contexam"><i class="fa fa-check"></i><b>7.6.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="sec-catoutcome.html"><a href="sec-catoutcome.html"><i class="fa fa-check"></i><b>7.7</b> Discrete outcome</a><ul>
<li class="chapter" data-level="7.7.1" data-path="sec-catoutcome.html"><a href="sec-catoutcome.html#methods-1"><i class="fa fa-check"></i><b>7.7.1</b> Methods</a></li>
<li class="chapter" data-level="7.7.2" data-path="sec-catoutcome.html"><a href="sec-catoutcome.html#example"><i class="fa fa-check"></i><b>7.7.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="sec-level2pred.html"><a href="sec-level2pred.html"><i class="fa fa-check"></i><b>7.8</b> Imputation of level-2 variable</a></li>
<li class="chapter" data-level="7.9" data-path="sec-comparative.html"><a href="sec-comparative.html"><i class="fa fa-check"></i><b>7.9</b> Comparative work</a></li>
<li class="chapter" data-level="7.10" data-path="sec-mlguidelines.html"><a href="sec-mlguidelines.html"><i class="fa fa-check"></i><b>7.10</b> Guidelines and advice</a><ul>
<li class="chapter" data-level="7.10.1" data-path="sec-mlguidelines.html"><a href="sec-mlguidelines.html#sec:emptymodel"><i class="fa fa-check"></i><b>7.10.1</b> Intercept-only model, missing outcomes</a></li>
<li class="chapter" data-level="7.10.2" data-path="sec-mlguidelines.html"><a href="sec-mlguidelines.html#sec:ri1pred"><i class="fa fa-check"></i><b>7.10.2</b> Random intercepts, missing level-1 predictor</a></li>
<li class="chapter" data-level="7.10.3" data-path="sec-mlguidelines.html"><a href="sec-mlguidelines.html#sec:wbg"><i class="fa fa-check"></i><b>7.10.3</b> Random intercepts, contextual model</a></li>
<li class="chapter" data-level="7.10.4" data-path="sec-mlguidelines.html"><a href="sec-mlguidelines.html#sec:ril2"><i class="fa fa-check"></i><b>7.10.4</b> Random intercepts, missing level-2 predictor</a></li>
<li class="chapter" data-level="7.10.5" data-path="sec-mlguidelines.html"><a href="sec-mlguidelines.html#sec:mlint"><i class="fa fa-check"></i><b>7.10.5</b> Random intercepts, interactions</a></li>
<li class="chapter" data-level="7.10.6" data-path="sec-mlguidelines.html"><a href="sec-mlguidelines.html#sec:randomslopes"><i class="fa fa-check"></i><b>7.10.6</b> Random slopes, missing outcomes and predictors</a></li>
<li class="chapter" data-level="7.10.7" data-path="sec-mlguidelines.html"><a href="sec-mlguidelines.html#sec:rsinteractions"><i class="fa fa-check"></i><b>7.10.7</b> Random slopes, interactions</a></li>
<li class="chapter" data-level="7.10.8" data-path="sec-mlguidelines.html"><a href="sec-mlguidelines.html#sec:recipes"><i class="fa fa-check"></i><b>7.10.8</b> Recipes</a></li>
</ul></li>
<li class="chapter" data-level="7.11" data-path="future-research.html"><a href="future-research.html"><i class="fa fa-check"></i><b>7.11</b> Future research</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-ice.html"><a href="ch-ice.html"><i class="fa fa-check"></i><b>8</b> Individual causal effects</a><ul>
<li class="chapter" data-level="8.1" data-path="sec-whyice.html"><a href="sec-whyice.html"><i class="fa fa-check"></i><b>8.1</b> Need for individual causal effects</a></li>
<li class="chapter" data-level="8.2" data-path="problem-of-causal-inference.html"><a href="problem-of-causal-inference.html"><i class="fa fa-check"></i><b>8.2</b> Problem of causal inference</a></li>
<li class="chapter" data-level="8.3" data-path="sec-iceframework.html"><a href="sec-iceframework.html"><i class="fa fa-check"></i><b>8.3</b> Framework</a></li>
<li class="chapter" data-level="8.4" data-path="generating-imputations-by-fcs.html"><a href="generating-imputations-by-fcs.html"><i class="fa fa-check"></i><b>8.4</b> Generating imputations by FCS</a><ul>
<li class="chapter" data-level="8.4.1" data-path="generating-imputations-by-fcs.html"><a href="generating-imputations-by-fcs.html#naive-fcs"><i class="fa fa-check"></i><b>8.4.1</b> Naive FCS</a></li>
<li class="chapter" data-level="8.4.2" data-path="generating-imputations-by-fcs.html"><a href="generating-imputations-by-fcs.html#sec:fcsprior"><i class="fa fa-check"></i><b>8.4.2</b> FCS with a prior for <span class="math inline">\(\rho\)</span></a></li>
<li class="chapter" data-level="8.4.3" data-path="generating-imputations-by-fcs.html"><a href="generating-imputations-by-fcs.html#sec:iceextensions"><i class="fa fa-check"></i><b>8.4.3</b> Extensions</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="bibliographic-notes.html"><a href="bibliographic-notes.html"><i class="fa fa-check"></i><b>8.5</b> Bibliographic notes</a></li>
</ul></li>
<li class="part"><span><b>III Part III: Case studies</b></span></li>
<li class="chapter" data-level="9" data-path="ch-measurement.html"><a href="ch-measurement.html"><i class="fa fa-check"></i><b>9</b> Measurement issues</a><ul>
<li class="chapter" data-level="9.1" data-path="sec-toomany.html"><a href="sec-toomany.html"><i class="fa fa-check"></i><b>9.1</b> Too many columns</a><ul>
<li class="chapter" data-level="9.1.1" data-path="sec-toomany.html"><a href="sec-toomany.html#sec:c85question"><i class="fa fa-check"></i><b>9.1.1</b> Scientific question</a></li>
<li class="chapter" data-level="9.1.2" data-path="sec-toomany.html"><a href="sec-toomany.html#sec:leiden85cohort"><i class="fa fa-check"></i><b>9.1.2</b> Leiden 85+ Cohort</a></li>
<li class="chapter" data-level="9.1.3" data-path="sec-toomany.html"><a href="sec-toomany.html#sec:exploration"><i class="fa fa-check"></i><b>9.1.3</b> Data exploration</a></li>
<li class="chapter" data-level="9.1.4" data-path="sec-toomany.html"><a href="sec-toomany.html#c85:influx"><i class="fa fa-check"></i><b>9.1.4</b> Outflux</a></li>
<li class="chapter" data-level="9.1.5" data-path="sec-toomany.html"><a href="sec-toomany.html#finding-problems-loggedevents"><i class="fa fa-check"></i><b>9.1.5</b> Finding problems: <code>loggedEvents</code></a></li>
<li class="chapter" data-level="9.1.6" data-path="sec-toomany.html"><a href="sec-toomany.html#quick-predictor-selection-quickpred"><i class="fa fa-check"></i><b>9.1.6</b> Quick predictor selection: <code>quickpred</code></a></li>
<li class="chapter" data-level="9.1.7" data-path="sec-toomany.html"><a href="sec-toomany.html#generating-the-imputations"><i class="fa fa-check"></i><b>9.1.7</b> Generating the imputations</a></li>
<li class="chapter" data-level="9.1.8" data-path="sec-toomany.html"><a href="sec-toomany.html#a-further-improvement-survival-as-predictor-variable"><i class="fa fa-check"></i><b>9.1.8</b> A further improvement: Survival as predictor variable</a></li>
<li class="chapter" data-level="9.1.9" data-path="sec-toomany.html"><a href="sec-toomany.html#some-guidance"><i class="fa fa-check"></i><b>9.1.9</b> Some guidance</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html"><i class="fa fa-check"></i><b>9.2</b> Sensitivity analysis</a><ul>
<li class="chapter" data-level="9.2.1" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#sec:c85causes"><i class="fa fa-check"></i><b>9.2.1</b> Causes and consequences of missing data</a></li>
<li class="chapter" data-level="9.2.2" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#scenarios"><i class="fa fa-check"></i><b>9.2.2</b> Scenarios</a></li>
<li class="chapter" data-level="9.2.3" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#generating-imputations-under-the-delta-adjustment"><i class="fa fa-check"></i><b>9.2.3</b> Generating imputations under the <span class="math inline">\(\delta\)</span>-adjustment</a></li>
<li class="chapter" data-level="9.2.4" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#complete-data-model"><i class="fa fa-check"></i><b>9.2.4</b> Complete-data model</a></li>
<li class="chapter" data-level="9.2.5" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#conclusion-6"><i class="fa fa-check"></i><b>9.2.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="sec-prevalence.html"><a href="sec-prevalence.html"><i class="fa fa-check"></i><b>9.3</b> Correct prevalence estimates from self-reported data</a><ul>
<li class="chapter" data-level="9.3.1" data-path="sec-prevalence.html"><a href="sec-prevalence.html#description-of-the-problem"><i class="fa fa-check"></i><b>9.3.1</b> Description of the problem</a></li>
<li class="chapter" data-level="9.3.2" data-path="sec-prevalence.html"><a href="sec-prevalence.html#sec:dontcount"><i class="fa fa-check"></i><b>9.3.2</b> Donâ€™t count on predictions</a></li>
<li class="chapter" data-level="9.3.3" data-path="sec-prevalence.html"><a href="sec-prevalence.html#the-main-idea"><i class="fa fa-check"></i><b>9.3.3</b> The main idea</a></li>
<li class="chapter" data-level="9.3.4" data-path="sec-prevalence.html"><a href="sec-prevalence.html#sec:srcdata"><i class="fa fa-check"></i><b>9.3.4</b> Data</a></li>
<li class="chapter" data-level="9.3.5" data-path="sec-prevalence.html"><a href="sec-prevalence.html#application"><i class="fa fa-check"></i><b>9.3.5</b> Application</a></li>
<li class="chapter" data-level="9.3.6" data-path="sec-prevalence.html"><a href="sec-prevalence.html#conclusion-7"><i class="fa fa-check"></i><b>9.3.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="sec-codingsystems.html"><a href="sec-codingsystems.html"><i class="fa fa-check"></i><b>9.4</b> Enhancing comparability</a><ul>
<li class="chapter" data-level="9.4.1" data-path="sec-codingsystems.html"><a href="sec-codingsystems.html#description-of-the-problem-1"><i class="fa fa-check"></i><b>9.4.1</b> Description of the problem</a></li>
<li class="chapter" data-level="9.4.2" data-path="sec-codingsystems.html"><a href="sec-codingsystems.html#sec:equating"><i class="fa fa-check"></i><b>9.4.2</b> Full dependence: Simple equating</a></li>
<li class="chapter" data-level="9.4.3" data-path="sec-codingsystems.html"><a href="sec-codingsystems.html#sec:walkingimputation"><i class="fa fa-check"></i><b>9.4.3</b> Independence: Imputation without a bridge study</a></li>
<li class="chapter" data-level="9.4.4" data-path="sec-codingsystems.html"><a href="sec-codingsystems.html#sec:untenable"><i class="fa fa-check"></i><b>9.4.4</b> Fully dependent or independent?</a></li>
<li class="chapter" data-level="9.4.5" data-path="sec-codingsystems.html"><a href="sec-codingsystems.html#sec:impbridge"><i class="fa fa-check"></i><b>9.4.5</b> Imputation using a bridge study</a></li>
<li class="chapter" data-level="9.4.6" data-path="sec-codingsystems.html"><a href="sec-codingsystems.html#sec:walkinginterpretation"><i class="fa fa-check"></i><b>9.4.6</b> Interpretation</a></li>
<li class="chapter" data-level="9.4.7" data-path="sec-codingsystems.html"><a href="sec-codingsystems.html#conclusion-8"><i class="fa fa-check"></i><b>9.4.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ex-ch-measurement.html"><a href="ex-ch-measurement.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-selection.html"><a href="ch-selection.html"><i class="fa fa-check"></i><b>10</b> Selection issues</a><ul>
<li class="chapter" data-level="10.1" data-path="sec-selective.html"><a href="sec-selective.html"><i class="fa fa-check"></i><b>10.1</b> Correcting for selective drop-out</a><ul>
<li class="chapter" data-level="10.1.1" data-path="sec-selective.html"><a href="sec-selective.html#pops-study-19-years-follow-up"><i class="fa fa-check"></i><b>10.1.1</b> POPS study: 19 years follow-up</a></li>
<li class="chapter" data-level="10.1.2" data-path="sec-selective.html"><a href="sec-selective.html#characterization-of-the-drop-out"><i class="fa fa-check"></i><b>10.1.2</b> Characterization of the drop-out</a></li>
<li class="chapter" data-level="10.1.3" data-path="sec-selective.html"><a href="sec-selective.html#sec:popsmodel"><i class="fa fa-check"></i><b>10.1.3</b> Imputation model</a></li>
<li class="chapter" data-level="10.1.4" data-path="sec-selective.html"><a href="sec-selective.html#sec:degenerate"><i class="fa fa-check"></i><b>10.1.4</b> A solution â€œthat does not look goodâ€</a></li>
<li class="chapter" data-level="10.1.5" data-path="sec-selective.html"><a href="sec-selective.html#results"><i class="fa fa-check"></i><b>10.1.5</b> Results</a></li>
<li class="chapter" data-level="10.1.6" data-path="sec-selective.html"><a href="sec-selective.html#conclusion-9"><i class="fa fa-check"></i><b>10.1.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="sec-nonresponse.html"><a href="sec-nonresponse.html"><i class="fa fa-check"></i><b>10.2</b> Correcting for nonresponse</a><ul>
<li class="chapter" data-level="10.2.1" data-path="sec-nonresponse.html"><a href="sec-nonresponse.html#fifth-dutch-growth-study"><i class="fa fa-check"></i><b>10.2.1</b> Fifth Dutch Growth Study</a></li>
<li class="chapter" data-level="10.2.2" data-path="sec-nonresponse.html"><a href="sec-nonresponse.html#nonresponse"><i class="fa fa-check"></i><b>10.2.2</b> Nonresponse</a></li>
<li class="chapter" data-level="10.2.3" data-path="sec-nonresponse.html"><a href="sec-nonresponse.html#comparison-to-known-population-totals"><i class="fa fa-check"></i><b>10.2.3</b> Comparison to known population totals</a></li>
<li class="chapter" data-level="10.2.4" data-path="sec-nonresponse.html"><a href="sec-nonresponse.html#sec:augmentsample"><i class="fa fa-check"></i><b>10.2.4</b> Augmenting the sample</a></li>
<li class="chapter" data-level="10.2.5" data-path="sec-nonresponse.html"><a href="sec-nonresponse.html#imputation-model"><i class="fa fa-check"></i><b>10.2.5</b> Imputation model</a></li>
<li class="chapter" data-level="10.2.6" data-path="sec-nonresponse.html"><a href="sec-nonresponse.html#sec:finalheight"><i class="fa fa-check"></i><b>10.2.6</b> Influence of nonresponse on final height</a></li>
<li class="chapter" data-level="10.2.7" data-path="sec-nonresponse.html"><a href="sec-nonresponse.html#discussion"><i class="fa fa-check"></i><b>10.2.7</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ex-ch-selection.html"><a href="ex-ch-selection.html"><i class="fa fa-check"></i><b>10.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-longitudinal.html"><a href="ch-longitudinal.html"><i class="fa fa-check"></i><b>11</b> Longitudinal data</a><ul>
<li class="chapter" data-level="11.1" data-path="sec-longandwide.html"><a href="sec-longandwide.html"><i class="fa fa-check"></i><b>11.1</b> Long and wide format</a></li>
<li class="chapter" data-level="11.2" data-path="sec-fdd.html"><a href="sec-fdd.html"><i class="fa fa-check"></i><b>11.2</b> SE Fireworks Disaster Study</a><ul>
<li class="chapter" data-level="11.2.1" data-path="sec-fdd.html"><a href="sec-fdd.html#intention-to-treat"><i class="fa fa-check"></i><b>11.2.1</b> Intention to treat</a></li>
<li class="chapter" data-level="11.2.2" data-path="sec-fdd.html"><a href="sec-fdd.html#imputation-model-1"><i class="fa fa-check"></i><b>11.2.2</b> Imputation model</a></li>
<li class="chapter" data-level="11.2.3" data-path="sec-fdd.html"><a href="sec-fdd.html#inspecting-imputations"><i class="fa fa-check"></i><b>11.2.3</b> Inspecting imputations</a></li>
<li class="chapter" data-level="11.2.4" data-path="sec-fdd.html"><a href="sec-fdd.html#complete-data-model-1"><i class="fa fa-check"></i><b>11.2.4</b> Complete-data model</a></li>
<li class="chapter" data-level="11.2.5" data-path="sec-fdd.html"><a href="sec-fdd.html#results-from-the-complete-data-model"><i class="fa fa-check"></i><b>11.2.5</b> Results from the complete-data model</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="sec-rastering.html"><a href="sec-rastering.html"><i class="fa fa-check"></i><b>11.3</b> Time raster imputation</a><ul>
<li class="chapter" data-level="11.3.1" data-path="sec-rastering.html"><a href="sec-rastering.html#change-score"><i class="fa fa-check"></i><b>11.3.1</b> Change score</a></li>
<li class="chapter" data-level="11.3.2" data-path="sec-rastering.html"><a href="sec-rastering.html#sec:tbcquestion"><i class="fa fa-check"></i><b>11.3.2</b> Scientific question: Critical periods</a></li>
<li class="chapter" data-level="11.3.3" data-path="sec-rastering.html"><a href="sec-rastering.html#sec:brokenstick"><i class="fa fa-check"></i><b>11.3.3</b> Broken stick model<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="11.3.4" data-path="sec-rastering.html"><a href="sec-rastering.html#terneuzen-birth-cohort"><i class="fa fa-check"></i><b>11.3.4</b> Terneuzen Birth Cohort</a></li>
<li class="chapter" data-level="11.3.5" data-path="sec-rastering.html"><a href="sec-rastering.html#sec:shrinkage"><i class="fa fa-check"></i><b>11.3.5</b> Shrinkage and the change score<span class="math inline">\(^\spadesuit\)</span></a></li>
<li class="chapter" data-level="11.3.6" data-path="sec-rastering.html"><a href="sec-rastering.html#sec:tbcimpute"><i class="fa fa-check"></i><b>11.3.6</b> Imputation</a></li>
<li class="chapter" data-level="11.3.7" data-path="sec-rastering.html"><a href="sec-rastering.html#complete-data-model-2"><i class="fa fa-check"></i><b>11.3.7</b> Complete-data model</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="conclusion-10.html"><a href="conclusion-10.html"><i class="fa fa-check"></i><b>11.4</b> Conclusion</a></li>
<li class="chapter" data-level="11.5" data-path="ex-ch-longitudinal.html"><a href="ex-ch-longitudinal.html"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Part IV: Extensions</b></span></li>
<li class="chapter" data-level="12" data-path="ch-conclusion.html"><a href="ch-conclusion.html"><i class="fa fa-check"></i><b>12</b> Conclusion</a><ul>
<li class="chapter" data-level="12.1" data-path="sec-limitations.html"><a href="sec-limitations.html"><i class="fa fa-check"></i><b>12.1</b> Some dangers, some doâ€™s and some donâ€™ts</a><ul>
<li class="chapter" data-level="12.1.1" data-path="sec-limitations.html"><a href="sec-limitations.html#some-dangers"><i class="fa fa-check"></i><b>12.1.1</b> Some dangers</a></li>
<li class="chapter" data-level="12.1.2" data-path="sec-limitations.html"><a href="sec-limitations.html#sec:dos"><i class="fa fa-check"></i><b>12.1.2</b> Some doâ€™s</a></li>
<li class="chapter" data-level="12.1.3" data-path="sec-limitations.html"><a href="sec-limitations.html#sec:donts"><i class="fa fa-check"></i><b>12.1.3</b> Some donâ€™ts</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="sec-reporting.html"><a href="sec-reporting.html"><i class="fa fa-check"></i><b>12.2</b> Reporting</a><ul>
<li class="chapter" data-level="12.2.1" data-path="sec-reporting.html"><a href="sec-reporting.html#sec:guidelines"><i class="fa fa-check"></i><b>12.2.1</b> Reporting guidelines</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec-reporting.html"><a href="sec-reporting.html#sec:template"><i class="fa fa-check"></i><b>12.2.2</b> Template</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sec-otherapps.html"><a href="sec-otherapps.html"><i class="fa fa-check"></i><b>12.3</b> Other applications</a><ul>
<li class="chapter" data-level="12.3.1" data-path="sec-otherapps.html"><a href="sec-otherapps.html#synthetic-datasets-for-data-protection"><i class="fa fa-check"></i><b>12.3.1</b> Synthetic datasets for data protection</a></li>
<li class="chapter" data-level="12.3.2" data-path="sec-otherapps.html"><a href="sec-otherapps.html#analysis-of-coarsened-data"><i class="fa fa-check"></i><b>12.3.2</b> Analysis of coarsened data</a></li>
<li class="chapter" data-level="12.3.3" data-path="sec-otherapps.html"><a href="sec-otherapps.html#file-matching-of-multiple-datasets"><i class="fa fa-check"></i><b>12.3.3</b> File matching of multiple datasets</a></li>
<li class="chapter" data-level="12.3.4" data-path="sec-otherapps.html"><a href="sec-otherapps.html#planned-missing-data-for-efficient-designs"><i class="fa fa-check"></i><b>12.3.4</b> Planned missing data for efficient designs</a></li>
<li class="chapter" data-level="12.3.5" data-path="sec-otherapps.html"><a href="sec-otherapps.html#adjusting-for-verification-bias"><i class="fa fa-check"></i><b>12.3.5</b> Adjusting for verification bias</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="sec-future.html"><a href="sec-future.html"><i class="fa fa-check"></i><b>12.4</b> Future developments</a><ul>
<li class="chapter" data-level="12.4.1" data-path="sec-future.html"><a href="sec-future.html#derived-variables"><i class="fa fa-check"></i><b>12.4.1</b> Derived variables</a></li>
<li class="chapter" data-level="12.4.2" data-path="sec-future.html"><a href="sec-future.html#algorithms-for-blocks-and-batches"><i class="fa fa-check"></i><b>12.4.2</b> Algorithms for blocks and batches</a></li>
<li class="chapter" data-level="12.4.3" data-path="sec-future.html"><a href="sec-future.html#nested-imputation"><i class="fa fa-check"></i><b>12.4.3</b> Nested imputation</a></li>
<li class="chapter" data-level="12.4.4" data-path="sec-future.html"><a href="sec-future.html#better-trials-with-dynamic-treatment-regimes"><i class="fa fa-check"></i><b>12.4.4</b> Better trials with dynamic treatment regimes</a></li>
<li class="chapter" data-level="12.4.5" data-path="sec-future.html"><a href="sec-future.html#sec:free"><i class="fa fa-check"></i><b>12.4.5</b> Distribution-free pooling rules</a></li>
<li class="chapter" data-level="12.4.6" data-path="sec-future.html"><a href="sec-future.html#improved-diagnostic-techniques"><i class="fa fa-check"></i><b>12.4.6</b> Improved diagnostic techniques</a></li>
<li class="chapter" data-level="12.4.7" data-path="sec-future.html"><a href="sec-future.html#building-block-in-modular-statistics"><i class="fa fa-check"></i><b>12.4.7</b> Building block in modular statistics</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="ex-ch-conclusion.html"><a href="ex-ch-conclusion.html"><i class="fa fa-check"></i><b>12.5</b> Exercises</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="technical-information.html"><a href="technical-information.html"><i class="fa fa-check"></i><b>A</b> Technical information</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org/yihui/bookdown/" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec:knowledge" class="section level2">
<h2><span class="header-section-number">6.4</span> Derived variables</h2>
<div id="sec:ratio" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Ratio of two variables</h3>
<p>In practice, there is often extra knowledge about the data that is not modeled explicitly. For example, consider the weight/height ratio <code>whr</code>, defined as <code>wgt</code>/<code>hgt</code> (kg/m). If any one of the triplet (<code>hgt</code>, <code>wgt</code>, <code>whr</code>) is missing, then the missing value can be calculated with certainty by a simple deterministic rule. Unless we specify otherwise, the imputation model is unaware of the relation between the three variables, and will produce imputations that are inconsistent with the rule. Inconsistent imputations are clearly undesirable since they yield combinations of data values that are impossible in the real world. Including knowledge about derived data in the imputation model prevents imputations from being inconsistent. Knowledge about the derived data can take many forms, and includes data transformations, interactions, sum scores, recoded versions, range restrictions, if-then relations and polynomials.</p>
<p>The easiest way to deal with the problem is to leave any derived data outside the imputation process. For example, we may impute any missing height and weight data, and append <code>whr</code> to the imputed data afterward. It is simple to do that in <code>mice</code> by</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span>boys[, <span class="kw">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;hgt&quot;</span>, <span class="st">&quot;wgt&quot;</span>, <span class="st">&quot;hc&quot;</span>, <span class="st">&quot;reg&quot;</span>)]
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(data, <span class="dt">print =</span> <span class="ot">FALSE</span>, <span class="dt">seed =</span> <span class="dv">71712</span>)
long &lt;-<span class="st"> </span>mice<span class="op">::</span><span class="kw">complete</span>(imp, <span class="st">&quot;long&quot;</span>, <span class="dt">include =</span> <span class="ot">TRUE</span>)
long<span class="op">$</span>whr &lt;-<span class="st"> </span><span class="kw">with</span>(long, <span class="dv">100</span> <span class="op">*</span><span class="st"> </span>wgt <span class="op">/</span><span class="st"> </span>hgt)
imp.itt &lt;-<span class="st"> </span><span class="kw">as.mids</span>(long)</code></pre></div>
<p>The approach is known as <em>Impute, then transform</em> <span class="citation">(Von Hippel <a href="references.html#ref-VONHIPPEL2009">2009</a>)</span>. While <code>whr</code> will be consistent, the obvious problem with this approach is that <code>whr</code> is not used by the imputation method, and hence biases the estimates of parameters related to <code>whr</code> towards zero. Note the use of the <code>as.mids</code> function, which transforms the imputed data <code>long</code> back into a <code>mids</code> object.</p>
<p>Another possibility is to create <code>whr</code> before imputation, and impute <code>whr</code> as just another variable, known as <em>JAV</em> <span class="citation">(White, Royston, and Wood <a href="references.html#ref-WHITE2011">2011</a>)</span>, or under the name <em>Transform, then impute</em> <span class="citation">(Von Hippel <a href="references.html#ref-VONHIPPEL2009">2009</a>)</span>. This is easy to do, as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data<span class="op">$</span>whr &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>data<span class="op">$</span>wgt <span class="op">/</span><span class="st"> </span>data<span class="op">$</span>hgt
imp.jav1 &lt;-<span class="st"> </span><span class="kw">mice</span>(data, <span class="dt">seed =</span> <span class="dv">32093</span>, <span class="dt">print =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>Warning: Number of logged events: 45</code></pre>
<p>The warning results from the linear dependencies among the predictors, which were introduced by adding <code>whr</code>. The <code>mice()</code> function checks for linear dependencies during the iterations, and temporarily removes predictors from the univariate imputation models where needed. Each removal action is documented in the the <code>loggedEvents</code> component of the <code>imp.jav1</code> object. The last three removal events are</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tail</span>(imp.jav1<span class="op">$</span>loggedEvents, <span class="dv">3</span>)</code></pre></div>
<pre><code>   it im dep meth out
43  5  4 whr  pmm wgt
44  5  5 wgt  pmm whr
45  5  5 whr  pmm wgt</code></pre>
<p>which informs us that <code>wgt</code> was removed while imputing <code>whr</code>, and vice versa. We may prevent automatic removal by setting the relevant entries in the <code>predictorMatrix</code> to zero.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-<span class="st"> </span><span class="kw">make.predictorMatrix</span>(data)
pred[<span class="kw">c</span>(<span class="st">&quot;wgt&quot;</span>, <span class="st">&quot;whr&quot;</span>), <span class="kw">c</span>(<span class="st">&quot;wgt&quot;</span>, <span class="st">&quot;whr&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">0</span>
pred[<span class="kw">c</span>(<span class="st">&quot;hgt&quot;</span>, <span class="st">&quot;whr&quot;</span>), <span class="kw">c</span>(<span class="st">&quot;hgt&quot;</span>, <span class="st">&quot;whr&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">0</span>
pred</code></pre></div>
<pre><code>    age hgt wgt hc reg whr
age   0   1   1  1   1   1
hgt   1   0   1  1   1   0
wgt   1   1   0  1   1   0
hc    1   1   1  0   1   1
reg   1   1   1  1   0   1
whr   1   0   0  1   1   0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp.jav2 &lt;-<span class="st"> </span><span class="kw">mice</span>(data, <span class="dt">pred =</span> pred, <span class="dt">seed =</span> <span class="dv">32093</span>, <span class="dt">print =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>This is a little faster (5-10%) and cleans out the warning.</p>
<p>A third approach is <em>Passive imputation</em>, where the transformation is done on-the-fly within the imputation algorithm. Since the transformed variable is available for imputation, the hope is that passive imputation removes the bias of the <em>Impute, then transform</em> methods, while restoring consistency among the imputations that was broken in <em>JAV</em>. Figure <a href="sec-knowledge.html#fig:passive">6.2</a> visualizes the consistency of the three methods.</p>
<p>In <code>mice</code> passive imputation is invoked by specifying the tilde symbol as the first character of the imputation method. This provides a simple method for specifying dependencies among the variables, such as transformed variables, recodes, interactions, sum scores and so on. In the above example, we invoke passive imputation by</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span>boys[, <span class="kw">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;hgt&quot;</span>, <span class="st">&quot;wgt&quot;</span>, <span class="st">&quot;hc&quot;</span>, <span class="st">&quot;reg&quot;</span>)]
data<span class="op">$</span>whr &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>data<span class="op">$</span>wgt <span class="op">/</span><span class="st"> </span>data<span class="op">$</span>hgt
meth &lt;-<span class="st"> </span><span class="kw">make.method</span>(data)
meth[<span class="st">&quot;whr&quot;</span>] &lt;-<span class="st"> &quot;~I(100 * wgt / hgt)&quot;</span>
pred &lt;-<span class="st"> </span><span class="kw">make.predictorMatrix</span>(data)
pred[<span class="kw">c</span>(<span class="st">&quot;wgt&quot;</span>, <span class="st">&quot;hgt&quot;</span>), <span class="st">&quot;whr&quot;</span>] &lt;-<span class="st"> </span><span class="dv">0</span>
imp.pas &lt;-<span class="st"> </span><span class="kw">mice</span>(data, <span class="dt">meth =</span> meth, <span class="dt">pred =</span> pred,
                <span class="dt">print =</span> <span class="ot">FALSE</span>, <span class="dt">seed =</span> <span class="dv">32093</span>)</code></pre></div>
<p>The <code>I()</code> operator in the <code>meth</code> definitions instructs <code>R</code> to interpret the argument as literal. So <code>I(100 * wgt / hgt)</code> calculates <code>whr</code> by dividing <code>wgt</code> by <code>hgt</code> (in meters). The imputed values for <code>whr</code> are thus derived from <code>hgt</code> and <code>wgt</code> according to the stated transformation, and hence are consistent. Since <code>whr</code> is that last column in the data, it is updated after <code>wgt</code> and <code>hgt</code> are imputed. The changes to the default predictor matrix are needed to break any feedback loops between the derived variables and their originals. It is important to do this since otherwise <code>whr</code> may contain absurd imputations and the algorithm may have difficulties in convergence.</p>
<div class="figure"><span id="fig:passive"></span>
<img src="fig/ch6-passive-1.png" alt="Three imputation models to impute weight/height ratio (whr). Methods Impute, then transform and Passive imputation respect the relation between whr and height (hgt) in the imputed data, whereas JAV does not." width="672" />
<p class="caption">
Figure 6.2: Three imputation models to impute weight/height ratio (<code>whr</code>). Methods <em>Impute, then transform</em> and <em>Passive imputation</em> respect the relation between <code>whr</code> and height (<code>hgt</code>) in the imputed data, whereas <em>JAV</em> does not.
</p>
</div>

<p>How well do these methods impute a ratio? The simulation studies by <span class="citation">Von Hippel (<a href="references.html#ref-VONHIPPEL2009">2009</a>)</span> and <span class="citation">Seaman, Bartlett, and White (<a href="references.html#ref-SEAMAN2012">2012</a>)</span> favored the use of <em>JAV</em>, but neither addressed imputation of the ratio of two variables. Let us look at a small simulation comparing the three methods. As the population data, take the 681 complete records of variables <code>age</code>, <code>hgt</code>, <code>wgt</code>, <code>hc</code> and <code>reg</code>, and create a model for predicting height circumference from <code>hc</code> from more easily measured variables, including <code>whr</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pop &lt;-<span class="st"> </span><span class="kw">na.omit</span>(boys[, <span class="kw">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;hgt&quot;</span>, <span class="st">&quot;wgt&quot;</span>, <span class="st">&quot;hc&quot;</span>, <span class="st">&quot;reg&quot;</span>)])
pop<span class="op">$</span>whr &lt;-<span class="st"> </span><span class="kw">with</span>(pop, <span class="dv">100</span> <span class="op">*</span><span class="st"> </span>wgt <span class="op">/</span><span class="st"> </span>hgt)
broom<span class="op">::</span><span class="kw">tidy</span>(<span class="kw">lm</span>(hc <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>hgt <span class="op">+</span><span class="st"> </span>wgt <span class="op">+</span><span class="st"> </span>whr, <span class="dt">data =</span> pop))</code></pre></div>
<pre><code># A tibble: 5 x 5
  term        estimate std.error statistic   p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept)   23.7     0.656       36.1  4.25e-160
2 age           -0.308   0.0538      -5.72 1.56e-  8
3 hgt            0.176   0.00736     24.0  2.41e- 92
4 wgt           -0.496   0.0284     -17.4  1.62e- 56
5 whr            1.06    0.0583      18.2  1.22e- 60</code></pre>
<p>This is a simple linear model, but the proportion of explained variance is very high, about 0.9. The ratio variable <code>whr</code> explains about 5% of the variance on top of the other variables. Let us randomly delete 25% of <code>hgt</code> and 25% of <code>wgt</code>, apply each of the three methods 200 times using <span class="math inline">\(m = 5\)</span>, and evaluate the parameter for <code>whr</code>.</p>
<table>
<caption><span id="tab:simratio">Table 6.2: </span> Evaluation of parameter for <code>whr</code> with 25% MCAR missing in <code>hgt</code> and 25% MCAR missing in <code>wgt</code> using four imputation strategies (<span class="math inline">\(n_\mathrm{sim} = 200\)</span>).</caption>
<thead>
<tr class="header">
<th align="left">Method</th>
<th align="center">Bias</th>
<th align="center">% Bias</th>
<th align="center">Coverage</th>
<th align="center">CI Width</th>
<th align="center">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><em>Impute, transform</em></td>
<td align="center">-0.28</td>
<td align="center">26.4</td>
<td align="center">0.09</td>
<td align="center">0.322</td>
<td align="center">0.289</td>
</tr>
<tr class="even">
<td align="left"><em>JAV</em></td>
<td align="center">-0.90</td>
<td align="center">84.5</td>
<td align="center">0.00</td>
<td align="center">0.182</td>
<td align="center">0.897</td>
</tr>
<tr class="odd">
<td align="left"><em>Passive imputation</em></td>
<td align="center">-0.28</td>
<td align="center">26.8</td>
<td align="center">0.06</td>
<td align="center">0.328</td>
<td align="center">0.293</td>
</tr>
<tr class="even">
<td align="left"><code>smcfcs</code></td>
<td align="center">-0.03</td>
<td align="center">2.6</td>
<td align="center">0.90</td>
<td align="center">0.334</td>
<td align="center">0.094</td>
</tr>
<tr class="odd">
<td align="left">Listwise deletion</td>
<td align="center">0.01</td>
<td align="center">0.7</td>
<td align="center">0.90</td>
<td align="center">0.307</td>
<td align="center">0.094</td>
</tr>
</tbody>
</table>
<p>Table <a href="sec-knowledge.html#tab:simratio">6.2</a> shows that all three methods have substantial negative biases. Method <em>JAV</em> almost nullifies the parameter. The other two methods are better, but still far from optimal. Actually, none of these methods can be recommended for imputing a ratio.</p>
<p><span class="citation">Bartlett et al. (<a href="references.html#ref-BARTLETT2015">2015</a>)</span> proposed a novel rejection sampling method that creates imputations that are congenial in the sense of <span class="citation">Meng (<a href="references.html#ref-MENG1994">1994</a>)</span> with the substantive (complete-data) model. The method was applied to squared terms and interactions, and here we investigate whether it extends to ratios. The method has been implemented in the <code>smcfcs</code> package. The imputation method requires a specification of the complete-data model, as arguments <code>smtype</code> and <code>smformula</code>. An example of how to generate imputations, fit models, and pool the results is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(smcfcs)
data &lt;-<span class="st"> </span>pop
data[<span class="kw">sample</span>(<span class="kw">nrow</span>(data), <span class="dt">size =</span> <span class="dv">100</span>), <span class="st">&quot;wgt&quot;</span>] &lt;-<span class="st"> </span><span class="ot">NA</span>
data[<span class="kw">sample</span>(<span class="kw">nrow</span>(data), <span class="dt">size =</span> <span class="dv">100</span>), <span class="st">&quot;hgt&quot;</span>] &lt;-<span class="st"> </span><span class="ot">NA</span>
data<span class="op">$</span>whr &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span>data<span class="op">$</span>wgt <span class="op">/</span><span class="st"> </span>data<span class="op">$</span>hgt
meth &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;norm&quot;</span>, <span class="st">&quot;norm&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;norm&quot;</span>)
imps &lt;-<span class="st"> </span><span class="kw">smcfcs</span>(<span class="dt">originaldata =</span> data, <span class="dt">meth =</span> meth, <span class="dt">smtype =</span> <span class="st">&quot;lm&quot;</span>,
               <span class="dt">smformula =</span> <span class="st">&quot;hc ~ age + hgt + wgt + whr&quot;</span>)
fit &lt;-<span class="st"> </span><span class="kw">lapply</span>(imps<span class="op">$</span>impDatasets, lm,
              <span class="dt">formula =</span> hc <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>hgt <span class="op">+</span><span class="st"> </span>wgt <span class="op">+</span><span class="st"> </span>whr)
<span class="kw">summary</span>(<span class="kw">pool</span>(fit))</code></pre></div>
<p>The results of the simulations are also in Table <a href="sec-knowledge.html#tab:simratio">6.2</a> under the heading of the <code>smcfcs</code>. The <code>smcfcs</code> method is far better than the three previous alternatives, and almost as good as one could wish for. Rejection sampling for imputation is still new and relatively unexplored, so this seems a promising area for further work.</p>
</div>
<div id="sec:interactions" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Interaction terms</h3>
<p>The standard MICE algorithm only models main effects. Sometimes the interaction between variables is of scientific interest. For example, in a longitudinal study we could be interested in assessing whether the rate of change differs between two treatment groups, in other words, the treatment-by-group interaction. The standard algorithm does not take interactions into account, so the interactions of interest should be added to the imputation model.</p>
<p>The usual type of interactions between two continuous variables is to subtract the mean and take the product. The following code adds an interaction betwen <code>wgt</code> and <code>hc</code> to the <code>boys</code> data and imputes the data by passive imputation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">expr &lt;-<span class="st"> </span><span class="kw">expression</span>((wgt <span class="op">-</span><span class="st"> </span><span class="dv">40</span>) <span class="op">*</span><span class="st"> </span>(hc <span class="op">-</span><span class="st"> </span><span class="dv">50</span>))
boys<span class="op">$</span>wgt.hc &lt;-<span class="st"> </span><span class="kw">with</span>(boys, <span class="kw">eval</span>(expr))
meth &lt;-<span class="st"> </span><span class="kw">make.method</span>(boys)
meth[<span class="st">&quot;wgt.hc&quot;</span>] &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;~I(&quot;</span>, expr, <span class="st">&quot;)&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
meth[<span class="st">&quot;bmi&quot;</span>] &lt;-<span class="st"> &quot;&quot;</span>
pred &lt;-<span class="st"> </span><span class="kw">make.predictorMatrix</span>(boys)
pred[<span class="kw">c</span>(<span class="st">&quot;wgt&quot;</span>, <span class="st">&quot;hc&quot;</span>), <span class="st">&quot;wgt.hc&quot;</span>] &lt;-<span class="st"> </span><span class="dv">0</span>
imp.int &lt;-<span class="st"> </span><span class="kw">mice</span>(boys, <span class="dt">m =</span> <span class="dv">1</span>, <span class="dt">meth =</span> meth, <span class="dt">pred =</span> pred,
                <span class="dt">print =</span> <span class="ot">FALSE</span>, <span class="dt">seed =</span> <span class="dv">62587</span>, <span class="dt">maxit =</span> <span class="dv">10</span>)</code></pre></div>
<div class="figure"><span id="fig:interaction"></span>
<img src="fig/ch6-interaction-1.png" alt="The relation between the interaction term wgt.hc (on the horizontal axes) and its components wgt and hc (on the vertical axes)." width="672" />
<p class="caption">
Figure 6.3: The relation between the interaction term <code>wgt.hc</code> (on the horizontal axes) and its components <code>wgt</code> and <code>hc</code> (on the vertical axes).
</p>
</div>

<p>Figure <a href="sec-knowledge.html#fig:interaction">6.3</a> illustrates that the scatterplots of the real and synthetic values are similar. Furthermore, the imputations adhere to the stated recipe <code>(wgt - 40) * (hc - 50)</code>. Interactions involving categorical variables can be done in similar ways <span class="citation">(Van Buuren and Groothuis-Oudshoorn <a href="references.html#ref-VANBUUREN2011B">2011</a>)</span>, for example by imputing the data in separate groups. One may do this in <code>mice</code> by splitting the dataset into two or more parts, run <code>mice()</code> on each part and then combine the imputed datasets with <code>rbind()</code>.</p>
<table>
<caption><span id="tab:siminteraction">Table 6.3: </span> Evaluation of parameter for <code>wgt.hc</code> with 25% MCAR missing in <code>hc</code> and 25% MCAR missing in <code>wgt</code> using four imputation strategies (<span class="math inline">\(n_\mathrm{sim} = 200\)</span>).</caption>
<thead>
<tr class="header">
<th align="left">Method</th>
<th align="right">Bias</th>
<th align="right">% Bias</th>
<th align="right">Coverage</th>
<th align="right">CI Width</th>
<th align="right">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><em>Impute, transform</em></td>
<td align="right">0.20</td>
<td align="right">22.7</td>
<td align="right">0.17</td>
<td align="right">0.290</td>
<td align="right">0.207</td>
</tr>
<tr class="even">
<td align="left"><em>JAV</em></td>
<td align="right">0.63</td>
<td align="right">71.5</td>
<td align="right">0.00</td>
<td align="right">0.229</td>
<td align="right">0.632</td>
</tr>
<tr class="odd">
<td align="left"><em>Passive imputation</em></td>
<td align="right">0.20</td>
<td align="right">22.6</td>
<td align="right">0.17</td>
<td align="right">0.283</td>
<td align="right">0.207</td>
</tr>
<tr class="even">
<td align="left"><code>scmfcs</code></td>
<td align="right">-0.01</td>
<td align="right">0.8</td>
<td align="right">0.92</td>
<td align="right">0.306</td>
<td align="right">0.083</td>
</tr>
<tr class="odd">
<td align="left">Listwise deletion</td>
<td align="right">-0.01</td>
<td align="right">0.8</td>
<td align="right">0.91</td>
<td align="right">0.237</td>
<td align="right">0.076</td>
</tr>
</tbody>
</table>
<p>Other methods for imputing interactions are <em>JAV</em>, <em>Impute, then transform</em> and <code>smcfcs</code>. Table <a href="sec-knowledge.html#tab:siminteraction">6.3</a> contains the results of simulations similar to those in Section <a href="sec-knowledge.html#sec:ratio">6.4.1</a>, but adapted to include the interaction effect shown in Figure <a href="sec-knowledge.html#fig:interaction">6.3</a> by using the complete-data model <code>lm(hgt wgt + hc + wgt.hc)</code>. The results tell the same story as before, with <code>smcfcs</code> the best method, followed by <em>Passive imputation</em> and <em>Impute, then transform</em>.</p>
<p><span class="citation">Von Hippel (<a href="references.html#ref-VONHIPPEL2009">2009</a>)</span> stated that <em>JAV</em> would give consistent results under MAR, but <span class="citation">Seaman, Bartlett, and White (<a href="references.html#ref-SEAMAN2012">2012</a>)</span> showed that consistency actually required MCAR. It is interesting that <span class="citation">Seaman, Bartlett, and White (<a href="references.html#ref-SEAMAN2012">2012</a>)</span> found that <em>JAV</em> generally performed better than passive imputation, which is not confirmed in our simulations. It is not quite clear where the difference comes from, but the discussion <em>JAV</em> versus passive pales somewhat in the light of <code>smcfcs</code>.</p>
<p>Generic methods to preserve interactions include tree-based regression and classification (Section <a href="sec-cart.html#sec:cart">3.5</a>) as well as various joint modeling methods (Section <a href="sec-JM.html#sec:JM">4.4</a>). The relative strengths and limitations of these approaches still need to be sorted out.</p>
</div>
<div id="sec:quadratic" class="section level3">
<h3><span class="header-section-number">6.4.3</span> Quadratic relations<span class="math inline">\(^\spadesuit\)</span></h3>
<p>One way to analyze nonlinear relations by a linear model is to include quadratic or cubic versions of the explanatory variables into the model. Creating imputed values under such models poses some challenges. Current imputation methodology either preserves the quadratic relation in the data and biases the estimates of interest, or provides unbiased estimates but does not preserve the quadratic relation <span class="citation">(Von Hippel <a href="references.html#ref-VONHIPPEL2009">2009</a>)</span>. It seems that we either have a congenial but misspecified model, or an uncongenial model that is specified correctly. This section describes an approach that aims to resolve this problem.</p>
<p>The model of scientific interest is</p>
<p><span class="math display" id="eq:quadratic">\[
X=\alpha + Y\beta_1 + Y^2\beta_2 + \epsilon \tag{6.1}
\]</span></p>
<p>with <span class="math inline">\(\epsilon\sim N(0,\sigma^2)\)</span>. We assume that <span class="math inline">\(X\)</span> is complete, and that <span class="math inline">\(Y=(Y_{\rm obs},Y_{\rm mis})\)</span> is partially missing. The problem is to find imputations for <span class="math inline">\(Y\)</span> such that estimates of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span> and <span class="math inline">\(\sigma^2\)</span> based on the imputed data are unbiased, while ensuring that the quadratic relation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(Y^2\)</span> will hold in the imputed data.</p>
<p>Define the <em>polynomial combination</em> <span class="math inline">\(Z\)</span> as <span class="math inline">\(Z = Y\beta_1 + Y^2\beta_2\)</span> for some <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>. The idea is to impute <span class="math inline">\(Z\)</span> instead of <span class="math inline">\(Y\)</span> and <span class="math inline">\(Y^2\)</span>, followed by a decomposition of the imputed data <span class="math inline">\(Z\)</span> into components <span class="math inline">\(Y\)</span> and <span class="math inline">\(Y^2\)</span>. Imputing <span class="math inline">\(Z\)</span> reduces the multivariate imputation problem to a univariate problem, which is easier to manage. Under the assumption that <span class="math inline">\(P(X,Z)\)</span> is multivariate normal, we can impute the missing part of <span class="math inline">\(Z\)</span> by Algorithm <a href="sec-linearnormal.html#def:norm">3.1</a>. In cases where a normal residual distribution is suspect, we replace the linear model by predictive mean matching. The next step is to decompose <span class="math inline">\(Z\)</span> into <span class="math inline">\(Y\)</span> and <span class="math inline">\(Y^2\)</span>. Under the model in Equation <a href="sec-knowledge.html#eq:quadratic">(6.1)</a> the value <span class="math inline">\(Y\)</span> has two roots:</p>
<span class="math display" id="eq:rightroot" id="eq:leftroot">\[\begin{align}
Y_- &amp;=- { 1 \over 2\beta_2 }  \left( \sqrt{4 \beta_2 Z + \beta_1^2} + \beta_1 \right)\tag{6.2}\\
Y_+ &amp;=  { 1 \over 2\beta_2 }  \left( \sqrt{4\beta_2 Z + \beta_1^2} - \beta_1 \right)\tag{6.3}
\end{align}\]</span>
<p>where we assume that the discriminant <span class="math inline">\(4\beta_2 Z + \beta_1^2\)</span> is larger than zero. For a given <span class="math inline">\(Z\)</span>, we can take either <span class="math inline">\(Y=Y_-\)</span> or <span class="math inline">\(Y=Y_+\)</span>, and square it to obtain <span class="math inline">\(Y^2\)</span>. Either root is consistent with <span class="math inline">\(Z = Y\beta_1 + Y^2\beta_2\)</span>, but the choice among these two options requires care. Suppose we choose <span class="math inline">\(Y_-\)</span> for all <span class="math inline">\(Z\)</span>. Then all <span class="math inline">\(Y\)</span> will correspond to points located on the left arm of the parabolic function. The minimum of the parabola is located at <span class="math inline">\(Y_{\rm min}=-\beta_1/2\beta_2\)</span>, so all imputations will occur in the left-hand side of the parabola. This is probably not intended.</p>
<p>The choice between the roots is made by random sampling. Let <span class="math inline">\(V\)</span> be a binary random variable defined as 1 if <span class="math inline">\(Y &gt; Y_{\rm min}\)</span>, and as 0 if <span class="math inline">\(Y \leq Y_{\rm min}\)</span>. Let us model the probability <span class="math inline">\(P(V=1)\)</span> by logistic regression as</p>
<p><span class="math display">\[
{\rm logit} (P(V=1)) = X\psi_X + Z\psi_Z + XZ\psi_{YZ}
\]</span></p>
<p>where the <span class="math inline">\(\psi\)</span>s are parameters in the logistic regression model. Under the assumption of ignorability, we calculate the predicted probability <span class="math inline">\(P(V=1)\)</span> from <span class="math inline">\(X_{\rm mis}\)</span> and <span class="math inline">\(Z_{\rm mis}\)</span>. As a final step, a random draw from the binomial distribution is made, and the corresponding (negative or positive) root is selected as the imputation. This is repeated for each missing value.</p>
<hr />

<div class="definition">
<p><span id="def:squares" class="definition"><strong>Algorithm 6.1  (Multiple imputation of quadratic terms.<span class="math inline">\(^\spadesuit\)</span>)  </strong></span></p>
<ol style="list-style-type: decimal">
<li><p>Calculate <span class="math inline">\(Y_\mathrm{obs}^2\)</span> for the observed <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Multiply impute <span class="math inline">\(Y_\mathrm{mis}\)</span> and <span class="math inline">\(Y_\mathrm{mis}^2\)</span> as if they were unrelated by linear regression or predictive mean matching, resulting in imputations <span class="math inline">\(\dot Y\)</span> and <span class="math inline">\(\dot Y^2\)</span>.</p></li>
<li><p>Estimate <span class="math inline">\(\hat\beta_1\)</span> and <span class="math inline">\(\hat\beta_2\)</span> by pooled linear regression of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y = (Y_\mathrm{obs},\dot Y)\)</span> and <span class="math inline">\(Y^2 = (Y_\mathrm{obs}^2,\dot Y^2)\)</span>.</p></li>
<li><p>Calculate the polynomial combination <span class="math inline">\(Z = Y\hat\beta_1 + Y^2\hat\beta_2\)</span>.</p></li>
<li><p>Multiply impute <span class="math inline">\(Z_\mathrm{mis}\)</span> by linear regression or predictive mean matching, resulting in imputed <span class="math inline">\(\dot Z\)</span>.</p></li>
<li><p>Calculate roots <span class="math inline">\(\dot Y_-\)</span> and <span class="math inline">\(\dot Y_+\)</span> given <span class="math inline">\(\hat\beta_1\)</span>, <span class="math inline">\(\hat\beta_2\)</span> and <span class="math inline">\(\dot Z\)</span> using Equations~ and .</p></li>
<li><p>Calculate the value on the horizontal axis at the parabolic minimum/maximum <span class="math inline">\(Y_\mathrm{min}=-\hat\beta_1/2\hat\beta_2\)</span>.</p></li>
<li><p>Calculate <span class="math inline">\(V_\mathrm{obs}=0\)</span> if <span class="math inline">\(Y_\mathrm{obs}\leq  Y_\mathrm{min}\)</span>, else <span class="math inline">\(V_{\rm obs}=1\)</span>.</p></li>
<li><p>Impute <span class="math inline">\(V_\mathrm{mis}\)</span> by logistic regression of <span class="math inline">\(V\)</span> given <span class="math inline">\(X\)</span>, <span class="math inline">\(Z\)</span> and <span class="math inline">\(XZ\)</span>, resulting in imputed <span class="math inline">\(\dot V\)</span>.</p></li>
<li><p>If <span class="math inline">\(\dot V&lt;0\)</span> then assign <span class="math inline">\(\dot Y=\dot Y_-\)</span>, else set <span class="math inline">\(\dot Y=\dot Y_+\)</span>.</p></li>
<li>Calculate <span class="math inline">\(\dot Y^2\)</span>.
</div>
</li>
</ol>

<hr />
<p>Algorithm <a href="sec-knowledge.html#def:squares">6.1</a> provides a detailed overview of all steps involved. The imputations <span class="math inline">\(\dot Z\)</span> satisfy <span class="math inline">\(\dot Z=\dot Y\hat\beta_1+\dot Y^2\hat\beta_2\)</span>, as required. The technique is available in <code>mice</code> as the method <code>quadratic</code>. The evaluation by <span class="citation">Vink and Van Buuren (<a href="references.html#ref-VINK2013">2013</a>)</span> showed that the method provided unbiased estimates under four types of extreme MAR mechanisms. The idea can be generalized to polynomial bases of higher orders.</p>
</div>
<div id="compositional-dataspadesuit" class="section level3">
<h3><span class="header-section-number">6.4.4</span> Compositional data<span class="math inline">\(^\spadesuit\)</span></h3>
<p>Sometimes we know that a set of variables should add up to a given total. If one of the additive terms is missing, we can directly calculate its value with certainty by deducting the known terms from the total. This is known as deductive imputation <span class="citation">(De Waal, Pannekoek, and Scholtus <a href="references.html#ref-DEWAAL2011">2011</a>)</span>. If two additive terms are missing, imputing one of these terms uses the available one degree of freedom, and hence implicitly determines the other term. Data of this type are known as compositional data, and they occur often in household and business surveys. Imputation of compositional data has only recently received attention <span class="citation">(Tempelman <a href="references.html#ref-TEMPELMAN2007">2007</a>; Hron, Templ, and Filzmoser <a href="references.html#ref-HRON2010">2010</a>; De Waal, Pannekoek, and Scholtus <a href="references.html#ref-DEWAAL2011">2011</a>; Vink, Lazendic, and Van Buuren <a href="references.html#ref-VINK2015">2015</a>)</span>. <span class="citation">Hron, Templ, and Filzmoser (<a href="references.html#ref-HRON2010">2010</a>)</span> proposed matching on the Aitchison distance, a measure specifically designed for compositional data. The method is available in <code>R</code> as the <code>robCompositions</code> package <span class="citation">(Templ, Hron, and Filzmoser <a href="references.html#ref-TEMPL2011B">2011</a>)</span>.</p>
<p>This section suggests a somewhat different method for imputing compositional data. Let <span class="math inline">\(Y_{123}= Y_1+Y_2+Y_3\)</span> be the known total score of the three variables <span class="math inline">\(Y_1\)</span>, <span class="math inline">\(Y_2\)</span> and <span class="math inline">\(Y_3\)</span>. We assume that <span class="math inline">\(Y_3\)</span> is complete and that <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> are jointly missing or observed. The problem is to create multiple imputations in <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> such that the sum of <span class="math inline">\(Y_1\)</span>, <span class="math inline">\(Y_2\)</span> and <span class="math inline">\(Y_3\)</span> equals a given total <span class="math inline">\(Y_{123}\)</span>, and such that parameters estimated from the imputed data are unbiased and have appropriate coverage.</p>
<p>Since <span class="math inline">\(Y_3\)</span> is known, we write <span class="math inline">\(Y_{12} = Y_{123} - Y_3\)</span> for the sum score <span class="math inline">\(Y_1+Y_2\)</span>. The key to the solution is to find appropriate values for the ratio <span class="math inline">\(P_1 = Y_1/Y_{12}\)</span>, or equivalently for <span class="math inline">\((1-P_1)=Y_2/Y_{12}\)</span>. Let <span class="math inline">\(P(P_1|Y_1^\mathrm{obs}, Y_2^\mathrm{obs}, Y_3, X)\)</span> denote the posterior distribution of <span class="math inline">\(P_1\)</span>, which is possibly dependent on the observed information. For each incomplete record, we make a random draw <span class="math inline">\(\dot P_1\)</span> from this distribution, and calculate imputations for <span class="math inline">\(Y_1\)</span> as <span class="math inline">\(\dot Y_1 = \dot P_1Y_{12}\)</span>. Likewise, imputations for <span class="math inline">\(Y_2\)</span> are calculated by <span class="math inline">\(\dot Y_2 = (1-\dot P_1)Y_{12}\)</span>. It is easy to show that <span class="math inline">\(\dot Y_1 + \dot Y_2 = Y_{12}\)</span>, and hence <span class="math inline">\(\dot Y_1 + \dot Y_2 + Y_3 = Y_{123}\)</span>, as required.</p>
<p>The best way in which the posterior should be specified has still to be determined. In this section we apply standard predictive mean matching. We study the properties of the method by a small simulation study. The first step is to create an artificial dataset with known properties as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">43112</span>)
n &lt;-<span class="st"> </span><span class="dv">400</span>
Y1 &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">size =</span> n, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
Y2 &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">size =</span> n, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
Y3 &lt;-<span class="st"> </span><span class="dv">10</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>Y1 <span class="op">+</span><span class="st"> </span><span class="fl">0.6</span> <span class="op">*</span><span class="st"> </span>Y2 <span class="op">+</span><span class="st"> </span><span class="kw">sample</span>(<span class="op">-</span><span class="dv">10</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">size =</span> n,
                                      <span class="dt">replace =</span> <span class="ot">TRUE</span>)
Y &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Y1, Y2, Y3)
Y[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] &lt;-<span class="st"> </span><span class="ot">NA</span>
<span class="kw">md.pattern</span>(Y, <span class="dt">plot =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>    Y3  Y1  Y2    
300  1   1   1   0
100  1   0   0   2
     0 100 100 200</code></pre>
<p>Thus, <code>Y</code> is a <span class="math inline">\(400 \times 3\)</span> dataset with 300 complete records and with 100 records in which both <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> are missing. Next, define three auxiliary variables that are needed for imputation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Y123 &lt;-<span class="st"> </span>Y1 <span class="op">+</span><span class="st"> </span>Y2 <span class="op">+</span><span class="st"> </span>Y3
Y12 &lt;-<span class="st"> </span>Y123 <span class="op">-</span><span class="st"> </span>Y[,<span class="dv">3</span>]
P1 &lt;-<span class="st"> </span>Y[,<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>Y12
data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Y, Y123, Y12, P1)</code></pre></div>
<p>where the naming of the variables corresponds to the total score <span class="math inline">\(Y_{123}\)</span>, the sum score <span class="math inline">\(Y_{12}\)</span> and the ratio <span class="math inline">\(P_1\)</span>.</p>
<p>The imputation model specifies how <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> depend on <span class="math inline">\(P_1\)</span> and <span class="math inline">\(Y_{12}\)</span> by means of passive imputation. The predictor matrix specifies that only <span class="math inline">\(Y_3\)</span> and <span class="math inline">\(Y_{12}\)</span> may be predictors of <span class="math inline">\(P_1\)</span> in order to avoid linear dependencies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">meth &lt;-<span class="st"> </span><span class="kw">make.method</span>(data)
meth[<span class="st">&quot;Y1&quot;</span>]  &lt;-<span class="st"> &quot;~ I(P1 * Y12)&quot;</span>
meth[<span class="st">&quot;Y2&quot;</span>]  &lt;-<span class="st"> &quot;~ I((1 - P1) * Y12)&quot;</span>
meth[<span class="st">&quot;Y12&quot;</span>] &lt;-<span class="st"> &quot;~ I(Y123 - Y3)&quot;</span>
pred &lt;-<span class="st"> </span><span class="kw">make.predictorMatrix</span>(data)
pred[<span class="st">&quot;P1&quot;</span>, ] &lt;-<span class="st"> </span><span class="dv">0</span>
pred[<span class="kw">c</span>(<span class="st">&quot;P1&quot;</span>), <span class="kw">c</span>(<span class="st">&quot;Y12&quot;</span>, <span class="st">&quot;Y3&quot;</span>)] &lt;-<span class="st"> </span><span class="dv">1</span>
imp1 &lt;-<span class="st"> </span><span class="kw">mice</span>(data, <span class="dt">meth =</span> meth, <span class="dt">pred =</span> pred, <span class="dt">m =</span> <span class="dv">10</span>,
             <span class="dt">print =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>The code <code>I(P1 * Y12)</code> calculates <span class="math inline">\(Y_1\)</span> as the product of <span class="math inline">\(P_1\)</span> and <span class="math inline">\(Y_{12}\)</span>, and so on. The pooled estimates are calculated as</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">summary</span>(<span class="kw">pool</span>(<span class="kw">with</span>(imp1, <span class="kw">lm</span>(Y3 <span class="op">~</span><span class="st"> </span>Y1 <span class="op">+</span><span class="st"> </span>Y2))))[, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], <span class="dv">2</span>)</code></pre></div>
<pre><code>            estimate std.error
(Intercept)     9.71      0.98
Y1              1.99      0.11
Y2              0.61      0.05</code></pre>
<p>The estimates are reasonably close to their true values of 10, 2 and 0.6, respectively. A small simulation study with these data using 100 simulations and <span class="math inline">\(m = 10\)</span> revealed average estimates of 9.94 (coverage 0.96), 1.95 (coverage 0.95) and 0.63 (coverage 0.91). Though not perfect, the estimates are close to the truth, while the data adhere to the summation rule.</p>
<div class="figure"><span id="fig:composition"></span>
<img src="fig/ch6-composition-1.png" alt="Distribution of \(P_1\) (relative contribution of \(Y_1\) to \(Y_1+Y_2\)) in the observed and imputed data at different levels of \(Y_1+Y_2\). The strong geometrical shape in the observed data is partially reproduced in the model that includes \(Y_3\)." width="672" />
<p class="caption">
Figure 6.4: Distribution of <span class="math inline">\(P_1\)</span> (relative contribution of <span class="math inline">\(Y_1\)</span> to <span class="math inline">\(Y_1+Y_2\)</span>) in the observed and imputed data at different levels of <span class="math inline">\(Y_1+Y_2\)</span>. The strong geometrical shape in the observed data is partially reproduced in the model that includes <span class="math inline">\(Y_3\)</span>.
</p>
</div>

<p>Figure <a href="sec-knowledge.html#fig:composition">6.4</a> shows where the solution might be further improved. The distribution of <span class="math inline">\(P_1\)</span> in the observed data is strongly patterned. This pattern is only partially reflected in the imputed <span class="math inline">\(\dot P_1\)</span> after predictive mean matching on both <span class="math inline">\(Y_{12}\)</span> and <span class="math inline">\(Y_3\)</span>. It is possible to imitate the pattern perfectly by removing <span class="math inline">\(Y_3\)</span> as a predictor for <span class="math inline">\(P_1\)</span>. However, this introduces bias in the parameter estimates. Evidently, some sort of compromise between these two options might further remove the remaining bias. This is an area for further research.</p>
<p>For a general missing data pattern, the procedure can be repeated for all pairs <span class="math inline">\((Y_j, Y_{j&#39;})\)</span> that have missing data. First create a consistent starting imputation that adheres to the rule of composition, then apply the above method to pairs <span class="math inline">\((Y_j, Y_{j&#39;})\)</span> that belong to the composition. This algorithm is a variation on the MICE algorithm with iterations occurring over pairs of variables rather than separate variables.</p>
<p><span class="citation">Vink (<a href="references.html#ref-VINK2015B">2015</a>)</span> extended these ideas to nested compositional data, where a given element of the composition is broken down into subelements. The method, called <em>predictive ratio matching</em>, calculates the ratio of two components, and then borrows imputations from donors that have a similar ratio. Component pairs are visited in an ingenious way and combined into an iterative algorithm.</p>
</div>
<div id="sec:sumscores" class="section level3">
<h3><span class="header-section-number">6.4.5</span> Sum scores</h3>
<p>The sum score is undefined if one of the variables to be added is missing. We can use sum scores of imputed variables within the MICE algorithm to economize on the number of predictors. For example, suppose we create a summary maturation score of the pubertal measurements <code>gen</code>, <code>phb</code> and <code>tv</code>, and use that score to impute the other variables instead of the three original pubertal measurements.</p>
<p>Another area of application is the imputation of test items that form a scale. When the number of items is small relative to the sample size, good results can be obtained by imputing the items in a full imputation model, where all items are used to impute others <span class="citation">(Van Buuren <a href="references.html#ref-VANBUUREN2010">2010</a>)</span>. This method becomes unfeasible for a larger number of items. In that case, one may structure the imputation problem assuming one knows which items belong to which scale. Suppose that the data consist of an outcome variable <code>out</code>, a background variable <code>bck</code>, a scale <code>a</code> with ten items <code>a1</code>-<code>a10</code>, a scale <code>b</code> with twelve items <code>b1</code>-<code>b12</code>, and that all variables contain missing values. After filling in starting imputations, the imputation model would take the following steps:</p>
<ol style="list-style-type: decimal">
<li><p>Impute <code>out</code> given <code>bck</code>, <code>a</code>, <code>b</code>, where <code>a</code> and <code>b</code> are the summed scale scores from <code>b1</code>-<code>b10</code> and <code>b1</code>-<code>b12</code>;</p></li>
<li><p>Impute <code>bck</code> given <code>out</code>, <code>a</code> and <code>b</code>;</p></li>
<li><p>Impute <code>a1</code> given <code>out</code>, <code>bck</code>, <code>b</code> and <code>a2</code>-<code>a10</code>;</p></li>
<li><p>Impute <code>a2</code> given <code>out</code>, <code>bck</code>, <code>b</code> and <code>a1</code>, <code>a3</code>-<code>a10</code>;</p></li>
<li><p>Impute <code>a3</code>-<code>a10</code> along the same way;</p></li>
<li><p>Impute <code>b1</code> given <code>out</code>, <code>bck</code>, <code>a</code> and <code>b2</code>-<code>b12</code>, where <code>a</code> is the updated summed scale score;</p></li>
<li><p>Impute <code>b2</code>-<code>b12</code> along the same way.</p></li>
</ol>
<p>This technique will condense the imputation model, so that it will become both faster and more stable. It is easy to specify such models in <code>mice</code>. See <span class="citation">Van Buuren and Groothuis-Oudshoorn (<a href="references.html#ref-VANBUUREN2011B">2011</a>)</span> for examples.</p>
<p><span class="citation">Plumpton et al. (<a href="references.html#ref-PLUMPTON2016">2016</a>)</span> found that the technique reduced the standard error on average by 39% compared to complete-case analysis, resulting in more precise conclusions. <span class="citation">Eekhout et al. (<a href="references.html#ref-EEKHOUT2018">2018</a>)</span> found that the technique outperforms existing techniques (complete-case analysis, imputing only total scores) with respect to bias and efficiency. As an alternative, one may use the mean of the observed items as the scale score (the parcel summary), which is easier than calculating the total score. Both studies obtained results that were comparable to using the total score. Note that the parcel summary mean requires the assumption that the missing items are MCAR, which may be problematic for speeded tests and for scales where items increase in difficulty. The magnitude of the effect of violations of the MCAR assumption on bias is still to be determined.</p>
</div>
<div id="conditional-imputation" class="section level3">
<h3><span class="header-section-number">6.4.6</span> Conditional imputation</h3>
<p>In some cases it makes sense to restrict the imputations, possibly conditional on other data. The method in Section <a href="sec-simplesolutions.html#sec:sri">1.3.5</a> produced negative values for the positive-valued variable <code>Ozone</code>. One way of dealing with this mismatch between the imputed and observed values is to censor the values at some specified minimum or maximum value. The <code>mice()</code> function has an argument called <code>post</code> that takes a vector of strings of <code>R</code> commands. These commands are parsed and evaluated just after the univariate imputation function returns, and thus provide a way to post-process the imputed values. Note that <code>post</code> only affects the synthetic values, and leaves the observed data untouched. The <code>squeeze()</code> function in <code>mice</code> replaces values beyond the specified bounds by the minimum and maximal scale values. A hacky way to ensure positive imputations for <code>Ozone</code> under stochastic regression imputation is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span>airquality[, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]
post &lt;-<span class="st"> </span><span class="kw">make.post</span>(data)
post[<span class="st">&quot;Ozone&quot;</span>] &lt;-
<span class="st">  &quot;imp[[j]][, i] &lt;- squeeze(imp[[j]][, i], c(1, 200))&quot;</span>
imp &lt;-<span class="st"> </span><span class="kw">mice</span>(data, <span class="dt">method =</span> <span class="st">&quot;norm.nob&quot;</span>, <span class="dt">m =</span> <span class="dv">1</span>,
            <span class="dt">maxit =</span> <span class="dv">1</span>, <span class="dt">seed =</span> <span class="dv">1</span>, <span class="dt">post =</span> post)</code></pre></div>
<div class="figure"><span id="fig:squeeze"></span>
<img src="fig/ch6-squeeze-1.png" alt="Stochastic regression imputation of Ozone, where the imputed values are restricted to the range 1â€“200. Compare to Figure 1.4." width="672" />
<p class="caption">
Figure 6.5: Stochastic regression imputation of <code>Ozone</code>, where the imputed values are restricted to the range 1â€“200. Compare to Figure <a href="sec-simplesolutions.html#fig:plotsri">1.4</a>.
</p>
</div>

<p>Compare Figure <a href="sec-knowledge.html#fig:squeeze">6.5</a> to Figure <a href="sec-simplesolutions.html#fig:plotsri">1.4</a>. The negative ozone value of -18.8 has now been replaced by a value of 1.</p>
<p>The previous syntax of the <code>post</code> argument is a bit cumbersome. The same result can be achieved by neater code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post[<span class="st">&quot;Ozone&quot;</span>] &lt;-<span class="st"> &quot;ifdo(c(Ozone &lt; 1, Ozone &gt; 200), c(1, 200))&quot;</span></code></pre></div>
<p>The <code>ifdo()</code> function is a convenient way to create conditional imputes. For example, in the <code>boys</code> data puberty is measured only for boys older than 8 years. Before this age it is unlikely that puberty has started. It is a good idea to bring this extra information into the imputation model to stabilize the solution. More precisely, we may restrict any imputations of <code>gen</code>, <code>phb</code> and <code>tv</code> to the lowest possible category for those boys younger than 8 years. This can be achieved by</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post &lt;-<span class="st"> </span><span class="kw">make.post</span>(boys)
post[<span class="st">&quot;gen&quot;</span>] &lt;-
<span class="st">  &quot;imp[[j]][data$age[!r[, j]] &lt; 8, i] &lt;- levels(boys$gen)[1]&quot;</span>
post[<span class="st">&quot;phb&quot;</span>] &lt;-
<span class="st">  &quot;imp[[j]][data$age[!r[, j]] &lt; 8, i] &lt;- levels(boys$phb)[1]&quot;</span>
post[<span class="st">&quot;tv&quot;</span>]  &lt;-<span class="st"> &quot;imp[[j]][data$age[!r[, j]] &lt; 8, i] &lt;- 1&quot;</span>
free &lt;-<span class="st"> </span><span class="kw">mice</span>(boys, <span class="dt">m =</span> <span class="dv">1</span>, <span class="dt">seed =</span> <span class="dv">85444</span>, <span class="dt">print =</span> <span class="ot">FALSE</span>)
restricted &lt;-<span class="st"> </span><span class="kw">mice</span>(boys, <span class="dt">m =</span> <span class="dv">1</span>, <span class="dt">post =</span> post, <span class="dt">seed =</span> <span class="dv">85444</span>,
                   <span class="dt">print =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure"><span id="fig:plotgen"></span>
<img src="fig/ch6-plotgen-1.png" alt="Genital development of Dutch boys by age. The free solution does not constrain the imputations, whereas the restricted solution requires all imputations below the age of 8 years to be at the lowest category." width="672" />
<p class="caption">
Figure 6.6: Genital development of Dutch boys by age. The free solution does not constrain the imputations, whereas the restricted solution requires all imputations below the age of 8 years to be at the lowest category.
</p>
</div>

<p>Figure <a href="sec-knowledge.html#fig:plotgen">6.6</a> compares the scatterplot of genital development against age for the free and restricted solutions. Around infancy and early childhood, the imputations generated under the free solution are clearly unrealistic due to the severe extrapolation of the data between the ages 0â€“8 years. The restricted solution remedies this situation by requiring that pubertal development does not start before the age of 8 years.</p>
<p>The post-processing facility provides almost limitless possibilities to customize the imputed values. For example, we could reset the imputed value in some subset of the missing data to <code>NA</code>, thus imputing only some of the variables. Of course, appropriate care is needed when using this partially imputed variable later on as a predictor. Another possibility is to add or multiply the imputed data by a given constant in the context of a sensitivity analysis for nonignorable missing data mechanisms (see Section <a href="sec-nonignorable.html#sec:nonignorable">3.8</a>). More generally, we might re-impute some entries in the dataset depending on their current value, thus opening up possibilities to specify methods for nonignorable missing data.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec-modelform.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec-algoptions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
